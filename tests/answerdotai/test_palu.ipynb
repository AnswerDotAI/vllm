{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02c91ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afee8aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.ops._C.paged_attention_mlrd_palu_v1??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11fb1726",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.ops._C.paged_attention_v1??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31238c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import _custom_ops as ops\n",
    "from vllm.utils import get_max_shared_memory_bytes, is_hip, seed_everything, create_kv_caches_with_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2898590",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FLOAT32_BYTES = torch.finfo(torch.float).bits // 8\n",
    "# This will change depending on the compute capability.\n",
    "# - 512 as a buffer\n",
    "# MAX_SEQ_LEN = get_max_shared_memory_bytes() // FLOAT32_BYTES - 512\n",
    "MAX_SEQ_LEN = 16\n",
    "# There may not be enough gpu memory due to large NUM_BLOCKS.\n",
    "# Reduce NUM_BLOCKS when it happens.\n",
    "NUM_BLOCKS = 4321  # Arbitrary values for testing\n",
    "PARTITION_SIZE = 512\n",
    "# flshattF and tritonflashattF supported: {torch.float16, torch.bfloat16}\n",
    "DTYPES = [torch.half, torch.bfloat16, torch.float\n",
    "          ] if not is_hip() else [torch.half, torch.bfloat16]\n",
    "NUM_GEN_SEQS = [7]  # Arbitrary values for testing\n",
    "NUM_PREFILL_SEQS = [3]  # Arbitrary values for testing\n",
    "NUM_HEADS = [(40, 40), (64, 8)]  # Arbitrary values for testing\n",
    "\n",
    "# FlashAttention forward only supports head dimension at most 128\n",
    "# https://github.com/ROCmSoftwarePlatform/flash-attention/blob/3d2b6f5d037782cc2c906909a46fb7e2e1b48b25/csrc/flash_attn_rocm/flash_api.cpp#L62\n",
    "HEAD_SIZES = [64, 80, 96, 112, 120, 128, 192, 256]\n",
    "\n",
    "BLOCK_SIZES = [16, 32]\n",
    "USE_ALIBI = [False, True]\n",
    "KV_CACHE_DTYPE = [\"auto\", \"fp8\"]\n",
    "SEEDS = [0]\n",
    "CUDA_DEVICES = [\n",
    "    f\"cuda:{i}\" for i in range(1 if torch.cuda.device_count() == 1 else 2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "15e5f899",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = (16, 8)\n",
    "num_seqs, num_query_heads, head_size = 4, 16, 128\n",
    "block_size = 32\n",
    "kv_cache_dtype = \"auto\"\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "13482506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed_everything(seed)\n",
    "dtype = torch.half\n",
    "device = \"cuda:0\"\n",
    "torch.set_default_device(device)\n",
    "scale = float(1.0 / (head_size**0.5))\n",
    "num_query_heads, num_kv_heads = num_heads\n",
    "query = torch.empty(num_seqs, num_query_heads, head_size, dtype=dtype)\n",
    "query.uniform_(-scale, scale)\n",
    "\n",
    "assert num_query_heads % num_kv_heads == 0\n",
    "num_queries_per_kv = num_query_heads // num_kv_heads\n",
    "# alibi_slopes = None\n",
    "# if use_alibi:\n",
    "#     alibi_slopes = torch.randn(num_query_heads, dtype=torch.float)\n",
    "\n",
    "seq_lens = [random.randint(1, MAX_SEQ_LEN) for _ in range(num_seqs)]\n",
    "seq_lens[-1] = MAX_SEQ_LEN\n",
    "max_seq_len = max(seq_lens)\n",
    "seq_lens = torch.tensor(seq_lens, dtype=torch.int)\n",
    "\n",
    "# Create the block tables.\n",
    "max_num_blocks_per_seq = (max_seq_len + block_size - 1) // block_size\n",
    "block_tables_lst = []\n",
    "for _ in range(num_seqs):\n",
    "    block_table = [\n",
    "        random.randint(0, NUM_BLOCKS - 1)\n",
    "        for _ in range(max_num_blocks_per_seq)\n",
    "    ]\n",
    "    block_tables_lst.append(block_table)\n",
    "\n",
    "block_tables = torch.tensor(block_tables_lst, dtype=torch.int)\n",
    "\n",
    "# Create the KV caches.\n",
    "key_caches, value_caches = create_kv_caches_with_random(NUM_BLOCKS, block_size, 1,\n",
    "                                                        num_kv_heads, head_size,\n",
    "                                                        kv_cache_dtype, dtype, seed,\n",
    "                                                        device)\n",
    "key_cache, value_cache = key_caches[0], value_caches[0]\n",
    "\n",
    "# Using default kv_scale\n",
    "k_scale = v_scale = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a5d7a077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4321, 8, 16, 32, 8]), torch.Size([4321, 8, 128, 32]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_cache.shape, value_cache.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0444d0b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [num_kv_heads, palu_head_size, head_size]\n",
    "palu_k_up_proj = torch.randn(5, 16, 128).to(dtype=dtype, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b4a3643a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 16, 128])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palu_k_up_proj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bf386204",
   "metadata": {},
   "outputs": [],
   "source": [
    "alibi_slopes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6b92b629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.40 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "75.9 μs ± 59.9 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "output = torch.empty_like(query)\n",
    "ops.paged_attention_mlrd_palu_v1(\n",
    "    output,\n",
    "    query,\n",
    "    key_cache,\n",
    "    palu_k_up_proj,\n",
    "    value_cache,\n",
    "    num_kv_heads,\n",
    "    scale,\n",
    "    block_tables,\n",
    "    seq_lens,\n",
    "    block_size,\n",
    "    max_seq_len,\n",
    "    alibi_slopes,\n",
    "    kv_cache_dtype,\n",
    "    k_scale,\n",
    "    v_scale,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3c723186",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0',\n",
       "       dtype=torch.float16)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "24084535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.25 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "74.1 μs ± 56.5 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "output = torch.empty_like(query)\n",
    "ops.paged_attention_v1(\n",
    "    output,\n",
    "    query,\n",
    "    key_cache,\n",
    "    value_cache,\n",
    "    num_kv_heads,\n",
    "    scale,\n",
    "    block_tables,\n",
    "    seq_lens,\n",
    "    block_size,\n",
    "    max_seq_len,\n",
    "    alibi_slopes,\n",
    "    kv_cache_dtype,\n",
    "    k_scale,\n",
    "    v_scale,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f1d10b1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.2141e-02,  3.2616e-03, -2.3148e-02,  ..., -3.5370e-02,\n",
       "          -1.2772e-02, -7.0190e-03],\n",
       "         [-2.2217e-02,  3.1929e-03, -2.3148e-02,  ..., -3.5461e-02,\n",
       "          -1.2871e-02, -6.9122e-03],\n",
       "         [ 3.7415e-02, -3.6392e-03, -4.5898e-02,  ...,  6.8665e-05,\n",
       "           4.7943e-02, -1.3275e-02],\n",
       "         ...,\n",
       "         [ 1.8997e-02, -1.2413e-02, -3.1982e-02,  ..., -5.6793e-02,\n",
       "           4.4800e-02,  2.9755e-02],\n",
       "         [ 1.3069e-02, -1.8433e-02,  4.1168e-02,  ...,  1.9741e-04,\n",
       "           6.8817e-03,  2.7420e-02],\n",
       "         [ 1.3123e-02, -1.8463e-02,  4.1351e-02,  ...,  1.0681e-04,\n",
       "           6.9847e-03,  2.7435e-02]],\n",
       "\n",
       "        [[-8.0688e-02,  1.5297e-02,  6.9214e-02,  ..., -5.4474e-02,\n",
       "          -5.7587e-02,  4.4769e-02],\n",
       "         [-8.0688e-02,  1.5297e-02,  6.9214e-02,  ..., -5.4474e-02,\n",
       "          -5.7587e-02,  4.4769e-02],\n",
       "         [ 7.6172e-02,  8.5876e-02, -8.7891e-02,  ...,  2.2278e-02,\n",
       "          -4.7755e-04,  7.1350e-02],\n",
       "         ...,\n",
       "         [ 3.8574e-02,  1.4069e-02,  4.4312e-02,  ..., -7.8003e-02,\n",
       "           7.9529e-02, -3.9551e-02],\n",
       "         [-8.5526e-03,  5.0049e-02,  3.8239e-02,  ...,  6.9519e-02,\n",
       "           6.1462e-02,  4.4006e-02],\n",
       "         [-8.5526e-03,  5.0049e-02,  3.8239e-02,  ...,  6.9519e-02,\n",
       "           6.1462e-02,  4.4006e-02]],\n",
       "\n",
       "        [[ 1.9531e-02,  1.5625e-02,  3.0518e-05,  ...,  3.4576e-02,\n",
       "          -2.9221e-03, -2.1000e-03],\n",
       "         [ 1.9547e-02,  1.5579e-02, -7.6294e-06,  ...,  3.4607e-02,\n",
       "          -2.9373e-03, -2.0943e-03],\n",
       "         [-5.4550e-04, -2.2247e-02, -4.1161e-03,  ...,  9.7322e-04,\n",
       "           2.6512e-03, -5.0774e-03],\n",
       "         ...,\n",
       "         [ 2.2339e-02, -5.9624e-03, -9.9716e-03,  ..., -4.1779e-02,\n",
       "          -1.7136e-02,  1.0071e-02],\n",
       "         [-1.4259e-02,  2.1454e-02, -8.4305e-03,  ...,  7.5531e-04,\n",
       "          -4.1870e-02, -1.7761e-02],\n",
       "         [-1.4275e-02,  2.1454e-02, -8.5068e-03,  ...,  8.1825e-04,\n",
       "          -4.1779e-02, -1.7822e-02]],\n",
       "\n",
       "        [[-6.3705e-03, -7.1487e-03, -1.1375e-02,  ..., -2.1225e-02,\n",
       "          -9.3460e-03,  5.1270e-03],\n",
       "         [-6.3972e-03, -7.1793e-03, -1.1421e-02,  ..., -2.1225e-02,\n",
       "          -9.3155e-03,  5.1346e-03],\n",
       "         [-8.3923e-03,  1.7670e-02, -3.3913e-03,  ...,  8.9874e-03,\n",
       "          -8.3847e-03, -8.0948e-03],\n",
       "         ...,\n",
       "         [ 1.4900e-02, -1.2207e-02, -8.0948e-03,  ..., -3.3493e-03,\n",
       "           1.4633e-02, -4.0550e-03],\n",
       "         [-3.8586e-03, -3.2234e-03, -5.1117e-03,  ...,  1.3397e-02,\n",
       "           1.6220e-02,  7.9956e-03],\n",
       "         [-3.8548e-03, -3.2425e-03, -5.1537e-03,  ...,  1.3344e-02,\n",
       "           1.6327e-02,  8.0338e-03]]], device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d3190b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509e53ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd94f095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
