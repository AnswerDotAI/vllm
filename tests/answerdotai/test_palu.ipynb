{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c91ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31238c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k/miniconda3/envs/vllm_dev/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-10-17 16:15:34,303\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from vllm import _custom_ops as ops\n",
    "from vllm.utils import get_max_shared_memory_bytes, is_hip, seed_everything, create_kv_caches_with_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2898590",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLOAT32_BYTES = torch.finfo(torch.float).bits // 8\n",
    "# This will change depending on the compute capability.\n",
    "# - 512 as a buffer\n",
    "# MAX_SEQ_LEN = get_max_shared_memory_bytes() // FLOAT32_BYTES - 512\n",
    "MAX_SEQ_LEN = 16\n",
    "# There may not be enough gpu memory due to large NUM_BLOCKS.\n",
    "# Reduce NUM_BLOCKS when it happens.\n",
    "NUM_BLOCKS = 4321  # Arbitrary values for testing\n",
    "PARTITION_SIZE = 512\n",
    "# flshattF and tritonflashattF supported: {torch.float16, torch.bfloat16}\n",
    "DTYPES = [torch.half, torch.bfloat16, torch.float\n",
    "          ] if not is_hip() else [torch.half, torch.bfloat16]\n",
    "NUM_GEN_SEQS = [7]  # Arbitrary values for testing\n",
    "NUM_PREFILL_SEQS = [3]  # Arbitrary values for testing\n",
    "NUM_HEADS = [(40, 40), (64, 8)]  # Arbitrary values for testing\n",
    "\n",
    "# FlashAttention forward only supports head dimension at most 128\n",
    "# https://github.com/ROCmSoftwarePlatform/flash-attention/blob/3d2b6f5d037782cc2c906909a46fb7e2e1b48b25/csrc/flash_attn_rocm/flash_api.cpp#L62\n",
    "HEAD_SIZES = [64, 80, 96, 112, 120, 128, 192, 256]\n",
    "\n",
    "BLOCK_SIZES = [16, 32]\n",
    "USE_ALIBI = [False, True]\n",
    "KV_CACHE_DTYPE = [\"auto\", \"fp8\"]\n",
    "SEEDS = [0]\n",
    "CUDA_DEVICES = [\n",
    "    f\"cuda:{i}\" for i in range(1 if torch.cuda.device_count() == 1 else 2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e5f899",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = (16, 8)\n",
    "num_seqs, num_query_heads, head_size = 4, 16, 128\n",
    "block_size = 32\n",
    "kv_cache_dtype = \"auto\"\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13482506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed_everything(seed)\n",
    "dtype = torch.half\n",
    "device = \"cuda:0\"\n",
    "torch.set_default_device(device)\n",
    "scale = float(1.0 / (head_size**0.5))\n",
    "num_query_heads, num_kv_heads = num_heads\n",
    "query = torch.empty(num_seqs, num_query_heads, head_size, dtype=dtype)\n",
    "query.uniform_(-scale, scale)\n",
    "\n",
    "assert num_query_heads % num_kv_heads == 0\n",
    "num_queries_per_kv = num_query_heads // num_kv_heads\n",
    "# alibi_slopes = None\n",
    "# if use_alibi:\n",
    "#     alibi_slopes = torch.randn(num_query_heads, dtype=torch.float)\n",
    "\n",
    "seq_lens = [random.randint(1, MAX_SEQ_LEN) for _ in range(num_seqs)]\n",
    "seq_lens[-1] = MAX_SEQ_LEN\n",
    "max_seq_len = max(seq_lens)\n",
    "seq_lens = torch.tensor(seq_lens, dtype=torch.int)\n",
    "\n",
    "# Create the block tables.\n",
    "max_num_blocks_per_seq = (max_seq_len + block_size - 1) // block_size\n",
    "block_tables_lst = []\n",
    "for _ in range(num_seqs):\n",
    "    block_table = [\n",
    "        random.randint(0, NUM_BLOCKS - 1)\n",
    "        for _ in range(max_num_blocks_per_seq)\n",
    "    ]\n",
    "    block_tables_lst.append(block_table)\n",
    "\n",
    "block_tables = torch.tensor(block_tables_lst, dtype=torch.int)\n",
    "\n",
    "# Create the KV caches.\n",
    "key_caches, value_caches = create_kv_caches_with_random(NUM_BLOCKS, block_size, 1,\n",
    "                                                        num_kv_heads, head_size,\n",
    "                                                        kv_cache_dtype, dtype, seed,\n",
    "                                                        device)\n",
    "key_cache, value_cache = key_caches[0], value_caches[0]\n",
    "\n",
    "# Using default kv_scale\n",
    "k_scale = v_scale = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d7a077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4321, 8, 16, 32, 8]), torch.Size([4321, 8, 128, 32]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_cache.shape, value_cache.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0444d0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [num_kv_heads, palu_head_size, head_size]\n",
    "palu_k_up_proj = torch.ones(num_kv_heads, head_size//8, head_size).to(dtype=dtype, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5f41e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]]], device='cuda:0',\n",
       "       dtype=torch.float16)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palu_k_up_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf386204",
   "metadata": {},
   "outputs": [],
   "source": [
    "alibi_slopes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd8b6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch.empty_like(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22c3bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5318e-05,  1.5318e-05,  1.5318e-05,  ...,  1.5318e-05,\n",
       "           1.5318e-05,  1.5318e-05],\n",
       "         [ 1.5318e-05,  1.5318e-05,  1.5318e-05,  ...,  1.5318e-05,\n",
       "           1.5318e-05,  1.5318e-05],\n",
       "         [ 1.5318e-05,  1.5318e-05,  1.5318e-05,  ...,  1.5318e-05,\n",
       "           1.5318e-05,  1.5318e-05],\n",
       "         ...,\n",
       "         [ 1.5318e-05,  1.5318e-05,  1.5318e-05,  ...,  1.5318e-05,\n",
       "           1.5318e-05,  1.5318e-05],\n",
       "         [ 1.5318e-05,  1.5318e-05,  1.5318e-05,  ...,  1.5318e-05,\n",
       "           1.5318e-05,  1.5318e-05],\n",
       "         [ 1.5318e-05,  1.5318e-05,  1.5318e-05,  ...,  1.5318e-05,\n",
       "           1.5318e-05,  1.5318e-05]],\n",
       "\n",
       "        [[ 1.5318e-05,  1.5318e-05,  1.5318e-05,  ...,  1.5318e-05,\n",
       "           1.5318e-05,  1.5318e-05],\n",
       "         [ 1.5318e-05,  1.5318e-05,  1.5318e-05,  ...,  1.5318e-05,\n",
       "           1.5318e-05,  1.5318e-05],\n",
       "         [ 1.5318e-05,  1.5318e-05,  1.5318e-05,  ...,  1.5318e-05,\n",
       "           1.5318e-05,  1.5318e-05],\n",
       "         ...,\n",
       "         [ 1.5318e-05,  1.5318e-05,  1.5318e-05,  ...,  1.5318e-05,\n",
       "           1.5318e-05,  1.5318e-05],\n",
       "         [ 1.5318e-05,  1.5318e-05,  1.5318e-05,  ...,  1.5318e-05,\n",
       "           1.5318e-05,  1.5318e-05],\n",
       "         [ 1.5318e-05,  1.5318e-05,  1.5318e-05,  ...,  1.5318e-05,\n",
       "           1.5318e-05,  1.5318e-05]],\n",
       "\n",
       "        [[ 2.0000e+00, -1.3994e+00,  7.8125e-03,  ...,  1.2607e+00,\n",
       "          -0.0000e+00, -1.0752e+00],\n",
       "         [ 2.0000e+00,  1.1787e+00,  2.0000e+00,  ...,  1.2607e+00,\n",
       "          -2.0000e+00,  1.3643e+00],\n",
       "         [-5.1200e+02,  8.3838e-01,  0.0000e+00,  ...,  1.3936e+00,\n",
       "           2.0000e+00,  1.3086e+00],\n",
       "         ...,\n",
       "         [-5.1200e+02,  1.1523e+00,  7.8125e-03,  ..., -1.3926e+00,\n",
       "           5.1200e+02,  1.2539e+00],\n",
       "         [ 2.0000e+00, -1.1885e+00,  5.1200e+02,  ..., -9.4141e-01,\n",
       "          -5.1200e+02,  1.4014e+00],\n",
       "         [-7.8125e-03, -1.1650e+00, -7.8125e-03,  ...,  1.3857e+00,\n",
       "          -7.8125e-03, -1.4033e+00]],\n",
       "\n",
       "        [[ 5.1200e+02, -1.1143e+00,  5.1200e+02,  ..., -1.2432e+00,\n",
       "           0.0000e+00,  1.3857e+00],\n",
       "         [-0.0000e+00,  1.3203e+00,  7.8125e-03,  ...,  1.2158e+00,\n",
       "          -2.0000e+00, -1.4111e+00],\n",
       "         [ 7.8125e-03, -1.3076e+00,  7.8125e-03,  ...,  1.2539e+00,\n",
       "           2.0000e+00,  1.3779e+00],\n",
       "         ...,\n",
       "         [ 2.0000e+00,  1.3320e+00,  0.0000e+00,  ...,  1.0322e+00,\n",
       "           5.1200e+02,  1.3105e+00],\n",
       "         [ 0.0000e+00,  1.4160e+00, -0.0000e+00,  ..., -1.0869e+00,\n",
       "          -7.8125e-03, -1.1895e+00],\n",
       "         [ 5.1200e+02,  1.1475e+00, -0.0000e+00,  ...,  1.3965e+00,\n",
       "          -7.8125e-03,  1.2988e+00]]], device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b92b629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -n 10\n",
    "output = torch.empty_like(query)\n",
    "ops.paged_attention_mlrd_palu_v1(\n",
    "    output,\n",
    "    query,\n",
    "    key_cache,\n",
    "    palu_k_up_proj,\n",
    "    value_cache,\n",
    "    num_kv_heads,\n",
    "    scale,\n",
    "    block_tables,\n",
    "    seq_lens,\n",
    "    block_size,\n",
    "    max_seq_len,\n",
    "    alibi_slopes,\n",
    "    kv_cache_dtype,\n",
    "    k_scale,\n",
    "    v_scale,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26f6d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0',\n",
       "       dtype=torch.float16)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6307870f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mall(output \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert not torch.all(output == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561bb383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 128])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c723186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 128])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24084535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -n 10\n",
    "output = torch.empty_like(query)\n",
    "ops.paged_attention_v1(\n",
    "    output,\n",
    "    query,\n",
    "    key_cache,\n",
    "    value_cache,\n",
    "    num_kv_heads,\n",
    "    scale,\n",
    "    block_tables,\n",
    "    seq_lens,\n",
    "    block_size,\n",
    "    max_seq_len,\n",
    "    alibi_slopes,\n",
    "    kv_cache_dtype,\n",
    "    k_scale,\n",
    "    v_scale,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d10b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0054, -0.0048, -0.0015,  ...,  0.0238, -0.0044, -0.0098],\n",
       "         [ 0.0054, -0.0048, -0.0015,  ...,  0.0238, -0.0044, -0.0098],\n",
       "         [-0.0051,  0.0019, -0.0152,  ...,  0.0002, -0.0081,  0.0030],\n",
       "         ...,\n",
       "         [ 0.0134,  0.0103,  0.0134,  ..., -0.0143, -0.0222,  0.0170],\n",
       "         [-0.0102, -0.0091,  0.0178,  ..., -0.0154,  0.0082, -0.0058],\n",
       "         [-0.0103, -0.0092,  0.0179,  ..., -0.0153,  0.0083, -0.0057]],\n",
       "\n",
       "        [[ 0.0057,  0.0132,  0.0216,  ...,  0.0173,  0.0064,  0.0083],\n",
       "         [ 0.0057,  0.0133,  0.0216,  ...,  0.0172,  0.0063,  0.0082],\n",
       "         [ 0.0148, -0.0280, -0.0303,  ...,  0.0019, -0.0021, -0.0257],\n",
       "         ...,\n",
       "         [ 0.0041, -0.0591, -0.0425,  ...,  0.0129,  0.0220, -0.0307],\n",
       "         [ 0.0197,  0.0287, -0.0024,  ...,  0.0050,  0.0005, -0.0061],\n",
       "         [ 0.0196,  0.0286, -0.0025,  ...,  0.0048,  0.0006, -0.0061]],\n",
       "\n",
       "        [[ 0.0138,  0.0034,  0.0209,  ..., -0.0127, -0.0015,  0.0013],\n",
       "         [ 0.0137,  0.0034,  0.0209,  ..., -0.0127, -0.0015,  0.0013],\n",
       "         [-0.0280, -0.0205,  0.0157,  ..., -0.0170, -0.0163,  0.0200],\n",
       "         ...,\n",
       "         [-0.0093, -0.0181, -0.0514,  ..., -0.0078,  0.0022, -0.0076],\n",
       "         [-0.0187,  0.0048,  0.0153,  ..., -0.0241,  0.0068, -0.0044],\n",
       "         [-0.0187,  0.0047,  0.0152,  ..., -0.0241,  0.0067, -0.0044]],\n",
       "\n",
       "        [[-0.0027,  0.0073,  0.0038,  ..., -0.0007,  0.0042, -0.0083],\n",
       "         [-0.0026,  0.0073,  0.0037,  ..., -0.0008,  0.0042, -0.0083],\n",
       "         [ 0.0130, -0.0034,  0.0013,  ..., -0.0130,  0.0276, -0.0110],\n",
       "         ...,\n",
       "         [ 0.0042, -0.0361,  0.0122,  ..., -0.0104,  0.0105, -0.0144],\n",
       "         [ 0.0029, -0.0025,  0.0083,  ...,  0.0155, -0.0046, -0.0202],\n",
       "         [ 0.0029, -0.0025,  0.0083,  ...,  0.0155, -0.0047, -0.0202]]],\n",
       "       device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d3190b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509e53ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd94f095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
