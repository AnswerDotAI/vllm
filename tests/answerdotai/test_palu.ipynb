{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c91ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31238c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k/miniconda3/envs/llm_quant/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-10-18 14:33:59,953\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from vllm import _custom_ops as ops\n",
    "from vllm.utils import get_max_shared_memory_bytes, is_hip, seed_everything, create_kv_caches_with_random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fcbd8d",
   "metadata": {},
   "source": [
    "### test random\n",
    "\n",
    "Test palu kernel random inputs.\n",
    "\n",
    "- Output should have some random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2898590",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLOAT32_BYTES = torch.finfo(torch.float).bits // 8\n",
    "# This will change depending on the compute capability.\n",
    "# - 512 as a buffer\n",
    "# MAX_SEQ_LEN = get_max_shared_memory_bytes() // FLOAT32_BYTES - 512\n",
    "MAX_SEQ_LEN = 16\n",
    "# There may not be enough gpu memory due to large NUM_BLOCKS.\n",
    "# Reduce NUM_BLOCKS when it happens.\n",
    "NUM_BLOCKS = 4321  # Arbitrary values for testing\n",
    "PARTITION_SIZE = 512\n",
    "# flshattF and tritonflashattF supported: {torch.float16, torch.bfloat16}\n",
    "DTYPES = [torch.half, torch.bfloat16, torch.float\n",
    "          ] if not is_hip() else [torch.half, torch.bfloat16]\n",
    "NUM_GEN_SEQS = [7]  # Arbitrary values for testing\n",
    "NUM_PREFILL_SEQS = [3]  # Arbitrary values for testing\n",
    "NUM_HEADS = [(40, 40), (64, 8)]  # Arbitrary values for testing\n",
    "\n",
    "# FlashAttention forward only supports head dimension at most 128\n",
    "# https://github.com/ROCmSoftwarePlatform/flash-attention/blob/3d2b6f5d037782cc2c906909a46fb7e2e1b48b25/csrc/flash_attn_rocm/flash_api.cpp#L62\n",
    "HEAD_SIZES = [64, 80, 96, 112, 120, 128, 192, 256]\n",
    "\n",
    "BLOCK_SIZES = [16, 32]\n",
    "USE_ALIBI = [False, True]\n",
    "KV_CACHE_DTYPE = [\"auto\", \"fp8\"]\n",
    "SEEDS = [0]\n",
    "CUDA_DEVICES = [\n",
    "    f\"cuda:{i}\" for i in range(1 if torch.cuda.device_count() == 1 else 2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e5f899",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = (16, 8)\n",
    "num_seqs, num_query_heads, head_size = 4, 16, 128\n",
    "block_size = 32\n",
    "kv_cache_dtype = \"auto\"\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80300fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "palu_head_size = head_size // 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13482506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed_everything(seed)\n",
    "dtype = torch.half\n",
    "device = \"cuda:0\"\n",
    "torch.set_default_device(device)\n",
    "scale = float(1.0 / (head_size**0.5))\n",
    "num_query_heads, num_kv_heads = num_heads\n",
    "query = torch.empty(num_seqs, num_query_heads, head_size, dtype=dtype)\n",
    "query.uniform_(-scale, scale)\n",
    "\n",
    "assert num_query_heads % num_kv_heads == 0\n",
    "num_queries_per_kv = num_query_heads // num_kv_heads\n",
    "# alibi_slopes = None\n",
    "# if use_alibi:\n",
    "#     alibi_slopes = torch.randn(num_query_heads, dtype=torch.float)\n",
    "\n",
    "seq_lens = [random.randint(1, MAX_SEQ_LEN) for _ in range(num_seqs)]\n",
    "seq_lens[-1] = MAX_SEQ_LEN\n",
    "max_seq_len = max(seq_lens)\n",
    "seq_lens = torch.tensor(seq_lens, dtype=torch.int)\n",
    "\n",
    "# Create the block tables.\n",
    "max_num_blocks_per_seq = (max_seq_len + block_size - 1) // block_size\n",
    "block_tables_lst = []\n",
    "for _ in range(num_seqs):\n",
    "    block_table = [\n",
    "        random.randint(0, NUM_BLOCKS - 1)\n",
    "        for _ in range(max_num_blocks_per_seq)\n",
    "    ]\n",
    "    block_tables_lst.append(block_table)\n",
    "\n",
    "block_tables = torch.tensor(block_tables_lst, dtype=torch.int)\n",
    "\n",
    "# Create the KV caches.\n",
    "key_caches, value_caches = create_kv_caches_with_random(NUM_BLOCKS, block_size, 1,\n",
    "                                                        num_kv_heads, palu_head_size,\n",
    "                                                        kv_cache_dtype, dtype, seed,\n",
    "                                                        device)\n",
    "key_cache, value_cache = key_caches[0], value_caches[0]\n",
    "\n",
    "# Using default kv_scale\n",
    "k_scale = v_scale = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d7a077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4321, 8, 2, 32, 8]), torch.Size([4321, 8, 16, 32]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_cache.shape, value_cache.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0444d0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [num_kv_heads, palu_head_size, head_size]\n",
    "palu_k_up_proj = torch.ones(num_kv_heads, head_size//8, head_size).to(dtype=dtype, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5f41e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert palu_k_up_proj.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf386204",
   "metadata": {},
   "outputs": [],
   "source": [
    "alibi_slopes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70546996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         ...,\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00]],\n",
       "\n",
       "        [[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         ...,\n",
       "         [1.8750e+00, 1.8750e+00, 1.8750e+00,  ..., 1.0510e-43,\n",
       "          1.2191e-43, 1.2472e-43],\n",
       "         [1.2752e-43, 1.4574e-43, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00]],\n",
       "\n",
       "        [[0.0000e+00, 1.8750e+00, 0.0000e+00,  ..., 1.8750e+00,\n",
       "          0.0000e+00, 1.8750e+00],\n",
       "         [0.0000e+00, 1.8750e+00, 0.0000e+00,  ..., 1.8750e+00,\n",
       "          0.0000e+00, 1.8750e+00],\n",
       "         [0.0000e+00, 1.8750e+00, 0.0000e+00,  ..., 1.8750e+00,\n",
       "          0.0000e+00, 1.8750e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 1.8750e+00, 0.0000e+00,  ..., 1.8750e+00,\n",
       "          0.0000e+00, 1.8750e+00],\n",
       "         [0.0000e+00, 1.8750e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          7.7071e-44, 0.0000e+00],\n",
       "         [7.8473e-44, 0.0000e+00, 7.9874e-44,  ..., 0.0000e+00,\n",
       "          8.8282e-44, 0.0000e+00]],\n",
       "\n",
       "        [[0.0000e+00, 1.9998e+00, 9.1084e-44,  ..., 0.0000e+00,\n",
       "          9.9492e-44, 0.0000e+00],\n",
       "         [1.0229e-43, 0.0000e+00, 1.0510e-43,  ..., 0.0000e+00,\n",
       "          1.2191e-43, 0.0000e+00],\n",
       "         [1.2472e-43, 0.0000e+00, 1.2752e-43,  ..., 0.0000e+00,\n",
       "          1.4574e-43, 0.0000e+00],\n",
       "         ...,\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00]]], device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = torch.empty(num_seqs, num_query_heads, palu_head_size); output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8487b091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -n 10\n",
    "ops.paged_attention_mlrd_palu_v1(\n",
    "    output,\n",
    "    query,\n",
    "    key_cache,\n",
    "    palu_k_up_proj,\n",
    "    value_cache,\n",
    "    num_kv_heads,\n",
    "    scale,\n",
    "    block_tables,\n",
    "    seq_lens,\n",
    "    block_size,\n",
    "    max_seq_len,\n",
    "    alibi_slopes,\n",
    "    kv_cache_dtype,\n",
    "    k_scale,\n",
    "    v_scale,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4055fcc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[0.0000e+00, 1.8750e+00, 0.0000e+00,  ..., 1.8750e+00,\n",
       "          0.0000e+00, 1.8750e+00],\n",
       "         [0.0000e+00, 1.8750e+00, 0.0000e+00,  ..., 1.8750e+00,\n",
       "          0.0000e+00, 1.8750e+00],\n",
       "         [0.0000e+00, 1.8750e+00, 0.0000e+00,  ..., 1.8750e+00,\n",
       "          0.0000e+00, 1.8750e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 1.8750e+00, 0.0000e+00,  ..., 1.8750e+00,\n",
       "          0.0000e+00, 1.8750e+00],\n",
       "         [0.0000e+00, 1.8750e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          7.7071e-44, 0.0000e+00],\n",
       "         [7.8473e-44, 0.0000e+00, 7.9874e-44,  ..., 0.0000e+00,\n",
       "          8.8282e-44, 0.0000e+00]],\n",
       "\n",
       "        [[0.0000e+00, 1.9998e+00, 9.1084e-44,  ..., 0.0000e+00,\n",
       "          9.9492e-44, 0.0000e+00],\n",
       "         [1.0229e-43, 0.0000e+00, 1.0510e-43,  ..., 0.0000e+00,\n",
       "          1.2191e-43, 0.0000e+00],\n",
       "         [1.2472e-43, 0.0000e+00, 1.2752e-43,  ..., 0.0000e+00,\n",
       "          1.4574e-43, 0.0000e+00],\n",
       "         ...,\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00]]], device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db20a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 16])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b93bc0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3668],\n",
       "         [ 185],\n",
       "         [2209],\n",
       "         [2856]], device='cuda:0', dtype=torch.int32),\n",
       " tensor([ 9,  3, 10, 16], device='cuda:0', dtype=torch.int32),\n",
       " torch.Size([4, 16, 128]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_tables, seq_lens, query.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262f7bd9",
   "metadata": {},
   "source": [
    "### test palu paged attn against paged attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91f13aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_seqs = 1\n",
    "num_blocks = num_seqs\n",
    "num_heads = 64\n",
    "\n",
    "num_kv_heads = 8\n",
    "head_size = 128\n",
    "palu_head_size = head_size // 4\n",
    "x = 8\n",
    "block_size = 32\n",
    "\n",
    "key_cache = torch.randn(num_blocks, num_kv_heads, palu_head_size//x, block_size, x,\n",
    "                        device=device, dtype=torch.half)\n",
    "value_cache = torch.randn(num_blocks, num_kv_heads, palu_head_size, block_size,\n",
    "                          device=device, dtype=torch.half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffdcfd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 4, 32, 8]), torch.Size([1, 8, 32, 32]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_cache.shape, value_cache.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5535e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = torch.randn(num_seqs, num_heads, head_size, device=device, dtype=torch.half)\n",
    "block_tables = torch.tensor([[0]], device=device, dtype=torch.int32)\n",
    "seq_lens = torch.tensor([4], device=device, dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0dd45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "palu_k_up_proj = torch.randn(num_kv_heads, palu_head_size, head_size, device=device, dtype=torch.half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5787543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 4\n",
    "alibi_slopes = None\n",
    "kv_cache_dtype = \"auto\"\n",
    "k_scale = v_scale = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b92b629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -n 10\n",
    "test_output = torch.empty(num_seqs, num_heads, palu_head_size)\n",
    "ops.paged_attention_mlrd_palu_v1(\n",
    "    test_output,\n",
    "    query,\n",
    "    key_cache,\n",
    "    palu_k_up_proj,\n",
    "    value_cache,\n",
    "    num_kv_heads,\n",
    "    scale,\n",
    "    block_tables,\n",
    "    seq_lens,\n",
    "    block_size,\n",
    "    max_seq_len,\n",
    "    alibi_slopes,\n",
    "    kv_cache_dtype,\n",
    "    k_scale,\n",
    "    v_scale,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ffda20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 32])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e627e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False, device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIXME: all output is zeros.\n",
    "torch.all(test_output==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a217d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 1.2741e-02,  1.4058e-09,  7.8694e-07,  ...,  1.0390e-02,\n",
       "          -1.0547e-03,  1.4940e-13],\n",
       "         [ 4.3596e-08,  7.5044e-13,  2.0900e-04,  ..., -3.6811e-03,\n",
       "          -1.1726e-05, -1.2618e-02],\n",
       "         [-1.2024e-05, -3.2733e-07,  1.4920e-06,  ...,  6.0168e-08,\n",
       "          -1.8650e-12, -7.8139e-07]]], device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62090b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we manually up project the \n",
    "key_cache_tmp = key_cache.permute(0,1,3,4,2).reshape(num_blocks, num_kv_heads, block_size, palu_head_size)\n",
    "key_cache_tmp = key_cache_tmp.permute(0,2,1,3).reshape(num_blocks*block_size, num_kv_heads, palu_head_size)\n",
    "\n",
    "# bmm: num_kv_heads, num_blocks*block_size, palu_head_size @ num_kv_heads, palu_head_size, head_size\n",
    "# -> num_kv_heads, num_blocks*block_size, head_size\n",
    "# permute: -> num_blocks*block_size, num_kv_heads, head_size\n",
    "key_cache_up = torch.bmm(key_cache_tmp.permute(1,0,2), palu_k_up_proj).permute(1,0,2)\n",
    "key_cache_up = key_cache_up.reshape(num_blocks, block_size, num_kv_heads, head_size//x, x)\n",
    "\n",
    "# to original shape: num_blocks, num_kv_heads, head_size//x, block_size, x\n",
    "key_cache_up = key_cache_up.permute(0,2,3,1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24084535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -n 10\n",
    "base_output = torch.empty(num_seqs, num_heads, palu_head_size)\n",
    "ops.paged_attention_v1(\n",
    "    base_output,\n",
    "    query,\n",
    "    key_cache_up,\n",
    "    value_cache,\n",
    "    num_kv_heads,\n",
    "    scale,\n",
    "    block_tables,\n",
    "    seq_lens,\n",
    "    block_size,\n",
    "    max_seq_len,\n",
    "    alibi_slopes,\n",
    "    kv_cache_dtype,\n",
    "    k_scale,\n",
    "    v_scale,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d10b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.4245e-03, -3.1543e-03, -1.5170e+00,  ...,  3.1979e-01,\n",
       "          -4.6233e-10,  9.9317e-04],\n",
       "         [-4.6809e-02, -3.9276e-05,  1.2437e-01,  ..., -3.6342e-03,\n",
       "           1.2656e-04, -2.8240e+00],\n",
       "         [ 9.7393e-05, -3.8031e-06, -4.9628e-07,  ..., -2.2337e+01,\n",
       "           5.0419e-03, -5.3989e-02],\n",
       "         ...,\n",
       "         [-1.1876e-05, -7.1635e-03, -4.7026e-05,  ...,  3.5705e-04,\n",
       "          -3.4625e-05, -7.1183e-01],\n",
       "         [-5.6910e-05, -1.0234e+01, -4.1433e-04,  ..., -7.5913e-03,\n",
       "          -5.5052e-06,  1.3659e-09],\n",
       "         [-1.8383e-06, -5.0255e-03,  9.9629e-03,  ...,  3.5924e-13,\n",
       "          -1.9391e-07,  5.5802e-06]]], device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d3190b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mequal(test_output, base_output)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert torch.equal(test_output, base_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509e53ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd94f095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
