{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c22d8c79-3add-4d49-9cae-e212b493467e",
   "metadata": {},
   "source": [
    "### BNB with Tensor Parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ff26655-6d13-479a-9af8-9d64083ec9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "from bitsandbytes.nn.modules import Params4bit, Linear4bit\n",
    "from bitsandbytes.functional import dequantize_4bit\n",
    "import bitsandbytes as bnb\n",
    "from bitsandbytes.functional import dequantize_4bit, QuantState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c906c609-2777-4148-acac-700d72842b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dea59055-c341-47c3-86b9-f48415d239d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocksize = 64\n",
    "quant_type = \"nf4\"\n",
    "quant_storage = torch.uint8\n",
    "\n",
    "data = torch.randn(128,256).to(torch.bfloat16)\n",
    "param = Params4bit(data, blocksize=blocksize, quant_type=quant_type, \n",
    "                   quant_storage=quant_storage, compress_statistics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b7929ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if quant_storage == torch.uint8:\n",
    "    pack_factor = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6890d631-c63f-4939-a5f4-00883a324aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "Parameter(Params4bit([[-0.1260, -1.6250,  0.0508,  ...,  0.3379, -1.7500,  1.1484],\n",
       "            [-0.2305, -1.3047, -2.0312,  ..., -0.1328, -0.3125,  1.8594],\n",
       "            [-1.1875,  0.9766,  0.0840,  ..., -2.2812,  0.6016,  1.1328],\n",
       "            ...,\n",
       "            [ 1.1875,  1.0234,  1.3281,  ...,  1.5781, -0.7227,  0.5156],\n",
       "            [ 0.0610, -0.3477,  1.2578,  ..., -1.7109,  1.0781,  0.6914],\n",
       "            [ 0.2002, -0.7422,  0.0527,  ...,  1.1953, -0.0952,  0.0854]],\n",
       "           dtype=torch.bfloat16))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "222fae9b-6520-46de-bd43-21867026cc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "920862c7-0c28-43cf-ba29-5a624eadaace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16384, 1]), 'nf4', torch.uint8, 64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param.shape, param.quant_type, param.quant_storage, param.blocksize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78e79d3e-ca1c-49e8-8da1-8578b346d2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16384, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a273b007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param.numel() / data.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a3b663b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quant_type': 'nf4',\n",
       " 'absmax': tensor([2.6406, 2.4062, 3.7812, 2.2344, 2.7500, 3.2500, 2.2500, 2.8594, 2.7656,\n",
       "         2.4688, 3.2969, 3.4844, 2.7812, 2.2188, 2.9375, 3.2812, 2.1094, 2.8125,\n",
       "         2.2344, 3.2344, 3.2188, 2.8125, 2.3906, 2.2812, 2.7031, 3.5938, 2.5156,\n",
       "         2.9219, 2.1875, 3.0469, 2.5781, 2.5781, 2.2188, 2.8125, 2.3281, 2.6094,\n",
       "         2.9219, 2.7344, 2.1719, 3.4375, 2.5000, 3.0625, 2.4688, 2.5625, 2.9531,\n",
       "         2.8125, 2.7969, 2.2500, 3.6094, 2.4062, 2.0781, 2.4531, 3.3281, 2.6250,\n",
       "         3.1250, 2.7969, 2.8594, 2.4844, 2.8906, 2.5000, 2.1719, 3.1406, 2.6094,\n",
       "         2.4375, 3.0000, 2.2188, 3.4062, 3.9688, 2.6250, 2.5938, 2.2500, 3.0000,\n",
       "         2.7188, 2.5625, 2.5156, 3.3750, 2.5469, 2.8125, 3.0781, 2.4688, 2.5781,\n",
       "         3.3281, 2.5781, 1.7109, 2.9375, 2.0781, 2.2031, 2.3750, 2.0312, 2.3750,\n",
       "         2.4688, 2.6406, 2.2812, 2.2344, 3.2031, 2.5312, 1.8203, 2.3438, 2.0625,\n",
       "         2.7500, 2.5312, 2.6094, 2.4844, 2.7188, 2.6562, 2.1094, 1.8594, 2.4688,\n",
       "         2.2188, 3.0312, 3.4062, 2.2031, 2.2188, 2.0000, 2.8438, 2.5156, 2.3594,\n",
       "         1.9844, 2.9531, 2.7344, 2.8750, 2.0156, 2.1406, 2.9844, 3.0312, 2.7344,\n",
       "         2.2656, 2.5938, 3.5625, 2.8750, 1.8672, 2.4531, 1.8672, 2.8281, 2.2500,\n",
       "         2.0312, 2.9375, 2.1719, 1.9531, 2.0938, 2.5625, 3.2812, 2.4375, 2.8750,\n",
       "         2.9062, 2.0469, 2.7188, 2.5000, 2.7500, 2.1094, 1.7344, 2.3750, 2.8281,\n",
       "         3.1250, 3.2344, 2.8906, 2.2344, 1.9844, 4.2812, 2.6562, 2.5938, 2.3750,\n",
       "         2.8750, 2.1719, 3.1250, 2.9219, 3.5469, 2.4844, 2.6250, 1.9922, 2.3125,\n",
       "         2.4844, 2.7656, 2.3281, 2.7969, 3.2656, 2.2188, 2.1875, 2.2500, 2.3906,\n",
       "         2.2344, 2.5156, 3.3125, 1.9922, 1.7344, 2.6406, 2.1406, 2.5000, 2.1562,\n",
       "         2.5469, 2.1875, 1.9219, 1.9609, 2.4219, 2.8438, 2.0938, 2.9062, 1.8750,\n",
       "         2.6719, 2.5312, 3.2969, 2.6250, 2.2812, 2.4219, 2.1875, 2.6719, 3.2656,\n",
       "         2.3906, 1.8281, 2.4844, 2.8438, 2.5156, 2.6562, 2.4219, 2.0000, 2.8906,\n",
       "         2.5312, 2.7188, 2.7500, 3.4375, 2.6094, 2.7500, 1.7734, 2.1250, 2.4531,\n",
       "         2.4688, 2.7812, 2.5469, 2.0312, 1.8906, 3.6406, 2.3281, 2.6094, 2.5938,\n",
       "         2.1562, 2.4531, 2.1719, 2.1406, 2.2969, 2.1406, 3.3906, 2.3594, 2.2812,\n",
       "         2.6250, 2.7812, 2.5938, 2.6562, 2.6250, 2.3750, 3.3750, 2.2500, 2.1719,\n",
       "         2.8750, 2.1719, 2.4375, 2.4062, 2.5469, 2.9688, 2.1719, 1.8906, 2.2812,\n",
       "         2.2969, 2.6875, 2.7656, 3.5312, 2.4844, 2.2812, 3.7656, 3.4375, 2.9531,\n",
       "         2.2031, 2.7812, 3.0781, 2.5625, 2.1875, 2.1562, 3.2344, 2.3438, 2.2969,\n",
       "         2.1875, 2.4844, 2.6719, 2.1562, 2.2969, 2.7812, 3.2969, 1.9688, 2.1719,\n",
       "         2.9219, 1.9609, 3.2969, 3.0312, 2.6562, 2.8438, 2.7656, 2.5156, 2.5312,\n",
       "         2.4375, 2.8750, 3.1250, 2.0938, 2.5312, 2.4062, 2.5938, 3.1406, 2.2812,\n",
       "         2.7188, 3.2812, 3.0781, 2.8750, 2.3906, 2.2344, 2.4062, 1.9922, 3.5312,\n",
       "         2.6250, 2.0625, 2.9375, 2.1875, 2.4062, 2.7500, 2.7188, 2.1250, 2.3125,\n",
       "         3.2656, 2.3281, 2.9375, 2.6719, 2.2188, 2.4844, 2.5781, 2.4375, 3.7031,\n",
       "         3.4844, 2.7188, 2.4688, 2.2969, 2.9219, 3.0000, 1.9219, 2.0312, 2.8125,\n",
       "         1.9766, 3.5938, 2.9844, 2.9219, 2.0938, 2.2188, 2.7188, 2.6094, 2.6406,\n",
       "         2.6562, 2.4688, 2.0156, 3.0156, 3.0625, 2.1250, 2.7188, 2.5000, 2.9531,\n",
       "         2.7188, 2.4375, 2.7031, 2.7188, 2.8594, 2.6719, 2.0156, 2.3281, 2.8750,\n",
       "         2.1562, 2.5312, 2.9062, 2.1250, 2.5938, 2.4688, 2.7812, 2.9219, 2.2188,\n",
       "         1.8516, 2.5938, 3.1406, 2.6719, 1.7656, 2.6250, 2.0156, 2.6875, 2.2500,\n",
       "         3.1719, 2.5000, 3.1250, 1.6875, 3.0000, 2.0625, 2.7500, 2.9844, 2.4844,\n",
       "         2.9375, 3.5000, 1.8906, 2.4219, 2.1406, 3.0312, 2.8125, 1.9922, 2.1562,\n",
       "         1.7656, 2.3281, 2.6094, 2.4531, 2.7500, 2.5156, 2.3281, 3.1875, 1.6953,\n",
       "         2.4219, 3.2812, 2.3438, 2.3281, 3.0781, 2.5000, 2.6719, 2.2812, 1.8281,\n",
       "         2.0781, 2.7656, 2.8438, 2.3594, 2.1875, 1.9297, 2.6562, 2.7344, 2.3594,\n",
       "         2.9062, 2.2969, 3.0469, 2.9531, 2.8281, 3.0625, 2.3438, 2.0000, 2.9219,\n",
       "         3.1875, 2.3906, 2.7344, 2.1719, 2.9219, 2.3906, 3.0469, 2.0938, 2.2031,\n",
       "         2.8906, 2.5156, 2.3125, 1.7734, 3.5156, 2.4688, 3.5000, 2.2969, 2.3750,\n",
       "         2.2188, 2.5625, 2.4375, 2.1250, 2.8750, 2.7031, 2.8594, 2.3125, 3.4531,\n",
       "         3.0938, 2.6094, 2.7656, 2.9062, 2.4375, 2.7031, 2.5781, 2.6094, 2.2812,\n",
       "         2.9375, 2.2031, 3.0156, 2.2812, 2.5625, 3.1406, 2.4062, 1.9062, 2.8438,\n",
       "         2.4375, 2.5156, 2.7031, 2.1406, 3.0469, 2.5469, 2.0469, 2.4062, 2.2344,\n",
       "         2.2188, 2.3594, 2.3438, 1.7656, 1.8984, 2.7656, 2.0938, 2.8125, 2.5625,\n",
       "         2.0781, 2.5312, 3.1562, 2.5000, 2.3438, 2.4062, 2.9375, 2.5312],\n",
       "        device='cuda:0'),\n",
       " 'blocksize': 64,\n",
       " 'quant_map': tensor([-1.0000, -0.6962, -0.5251, -0.3949, -0.2844, -0.1848, -0.0911,  0.0000,\n",
       "          0.0796,  0.1609,  0.2461,  0.3379,  0.4407,  0.5626,  0.7230,  1.0000],\n",
       "        device='cuda:0'),\n",
       " 'dtype': 'bfloat16',\n",
       " 'shape': (128, 256)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param.quant_state.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b110f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size_per_partition = 64\n",
    "output_size_per_partition = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35c5479f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# row-major quantization, reshape for vllm tensor parallelism\n",
    "qweight = param.data.reshape(data.size(0), data.size(1) // pack_factor); qweight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd34c2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 97, 119,  55,  ...,  65, 201,  29],\n",
       "        [ 98,  24,  97,  ..., 156, 134, 110],\n",
       "        [ 59, 112,  71,  ...,  58,  81, 155],\n",
       "        ...,\n",
       "        [203, 201, 227,  ...,  20, 173,  73],\n",
       "        [117, 217, 181,  ...,  65,  97, 202],\n",
       "        [132, 122, 134,  ...,  38,  44, 119]], device='cuda:0',\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b3a5601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 97],\n",
       "        [119],\n",
       "        [ 55],\n",
       "        ...,\n",
       "        [ 38],\n",
       "        [ 44],\n",
       "        [119]], device='cuda:0', dtype=torch.uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qweight.view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11e42bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "deqweight = dequantize_4bit(qweight.view(-1,1), param.quant_state, blocksize=blocksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e794c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(254., dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data - torch.randn_like(data)).norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4c3eb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(16.5000, dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data - deqweight.cpu()).norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c66129c-c120-4b67-bf0c-fee3d8e94a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(4, 128).cuda().to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed100e7d-5097-4682-9a6d-333f4434c877",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quant_type': 'nf4',\n",
       " 'absmax': tensor([2.6406, 2.4062, 3.7812, 2.2344, 2.7500, 3.2500, 2.2500, 2.8594, 2.7656,\n",
       "         2.4688, 3.2969, 3.4844, 2.7812, 2.2188, 2.9375, 3.2812, 2.1094, 2.8125,\n",
       "         2.2344, 3.2344, 3.2188, 2.8125, 2.3906, 2.2812, 2.7031, 3.5938, 2.5156,\n",
       "         2.9219, 2.1875, 3.0469, 2.5781, 2.5781, 2.2188, 2.8125, 2.3281, 2.6094,\n",
       "         2.9219, 2.7344, 2.1719, 3.4375, 2.5000, 3.0625, 2.4688, 2.5625, 2.9531,\n",
       "         2.8125, 2.7969, 2.2500, 3.6094, 2.4062, 2.0781, 2.4531, 3.3281, 2.6250,\n",
       "         3.1250, 2.7969, 2.8594, 2.4844, 2.8906, 2.5000, 2.1719, 3.1406, 2.6094,\n",
       "         2.4375, 3.0000, 2.2188, 3.4062, 3.9688, 2.6250, 2.5938, 2.2500, 3.0000,\n",
       "         2.7188, 2.5625, 2.5156, 3.3750, 2.5469, 2.8125, 3.0781, 2.4688, 2.5781,\n",
       "         3.3281, 2.5781, 1.7109, 2.9375, 2.0781, 2.2031, 2.3750, 2.0312, 2.3750,\n",
       "         2.4688, 2.6406, 2.2812, 2.2344, 3.2031, 2.5312, 1.8203, 2.3438, 2.0625,\n",
       "         2.7500, 2.5312, 2.6094, 2.4844, 2.7188, 2.6562, 2.1094, 1.8594, 2.4688,\n",
       "         2.2188, 3.0312, 3.4062, 2.2031, 2.2188, 2.0000, 2.8438, 2.5156, 2.3594,\n",
       "         1.9844, 2.9531, 2.7344, 2.8750, 2.0156, 2.1406, 2.9844, 3.0312, 2.7344,\n",
       "         2.2656, 2.5938, 3.5625, 2.8750, 1.8672, 2.4531, 1.8672, 2.8281, 2.2500,\n",
       "         2.0312, 2.9375, 2.1719, 1.9531, 2.0938, 2.5625, 3.2812, 2.4375, 2.8750,\n",
       "         2.9062, 2.0469, 2.7188, 2.5000, 2.7500, 2.1094, 1.7344, 2.3750, 2.8281,\n",
       "         3.1250, 3.2344, 2.8906, 2.2344, 1.9844, 4.2812, 2.6562, 2.5938, 2.3750,\n",
       "         2.8750, 2.1719, 3.1250, 2.9219, 3.5469, 2.4844, 2.6250, 1.9922, 2.3125,\n",
       "         2.4844, 2.7656, 2.3281, 2.7969, 3.2656, 2.2188, 2.1875, 2.2500, 2.3906,\n",
       "         2.2344, 2.5156, 3.3125, 1.9922, 1.7344, 2.6406, 2.1406, 2.5000, 2.1562,\n",
       "         2.5469, 2.1875, 1.9219, 1.9609, 2.4219, 2.8438, 2.0938, 2.9062, 1.8750,\n",
       "         2.6719, 2.5312, 3.2969, 2.6250, 2.2812, 2.4219, 2.1875, 2.6719, 3.2656,\n",
       "         2.3906, 1.8281, 2.4844, 2.8438, 2.5156, 2.6562, 2.4219, 2.0000, 2.8906,\n",
       "         2.5312, 2.7188, 2.7500, 3.4375, 2.6094, 2.7500, 1.7734, 2.1250, 2.4531,\n",
       "         2.4688, 2.7812, 2.5469, 2.0312, 1.8906, 3.6406, 2.3281, 2.6094, 2.5938,\n",
       "         2.1562, 2.4531, 2.1719, 2.1406, 2.2969, 2.1406, 3.3906, 2.3594, 2.2812,\n",
       "         2.6250, 2.7812, 2.5938, 2.6562, 2.6250, 2.3750, 3.3750, 2.2500, 2.1719,\n",
       "         2.8750, 2.1719, 2.4375, 2.4062, 2.5469, 2.9688, 2.1719, 1.8906, 2.2812,\n",
       "         2.2969, 2.6875, 2.7656, 3.5312, 2.4844, 2.2812, 3.7656, 3.4375, 2.9531,\n",
       "         2.2031, 2.7812, 3.0781, 2.5625, 2.1875, 2.1562, 3.2344, 2.3438, 2.2969,\n",
       "         2.1875, 2.4844, 2.6719, 2.1562, 2.2969, 2.7812, 3.2969, 1.9688, 2.1719,\n",
       "         2.9219, 1.9609, 3.2969, 3.0312, 2.6562, 2.8438, 2.7656, 2.5156, 2.5312,\n",
       "         2.4375, 2.8750, 3.1250, 2.0938, 2.5312, 2.4062, 2.5938, 3.1406, 2.2812,\n",
       "         2.7188, 3.2812, 3.0781, 2.8750, 2.3906, 2.2344, 2.4062, 1.9922, 3.5312,\n",
       "         2.6250, 2.0625, 2.9375, 2.1875, 2.4062, 2.7500, 2.7188, 2.1250, 2.3125,\n",
       "         3.2656, 2.3281, 2.9375, 2.6719, 2.2188, 2.4844, 2.5781, 2.4375, 3.7031,\n",
       "         3.4844, 2.7188, 2.4688, 2.2969, 2.9219, 3.0000, 1.9219, 2.0312, 2.8125,\n",
       "         1.9766, 3.5938, 2.9844, 2.9219, 2.0938, 2.2188, 2.7188, 2.6094, 2.6406,\n",
       "         2.6562, 2.4688, 2.0156, 3.0156, 3.0625, 2.1250, 2.7188, 2.5000, 2.9531,\n",
       "         2.7188, 2.4375, 2.7031, 2.7188, 2.8594, 2.6719, 2.0156, 2.3281, 2.8750,\n",
       "         2.1562, 2.5312, 2.9062, 2.1250, 2.5938, 2.4688, 2.7812, 2.9219, 2.2188,\n",
       "         1.8516, 2.5938, 3.1406, 2.6719, 1.7656, 2.6250, 2.0156, 2.6875, 2.2500,\n",
       "         3.1719, 2.5000, 3.1250, 1.6875, 3.0000, 2.0625, 2.7500, 2.9844, 2.4844,\n",
       "         2.9375, 3.5000, 1.8906, 2.4219, 2.1406, 3.0312, 2.8125, 1.9922, 2.1562,\n",
       "         1.7656, 2.3281, 2.6094, 2.4531, 2.7500, 2.5156, 2.3281, 3.1875, 1.6953,\n",
       "         2.4219, 3.2812, 2.3438, 2.3281, 3.0781, 2.5000, 2.6719, 2.2812, 1.8281,\n",
       "         2.0781, 2.7656, 2.8438, 2.3594, 2.1875, 1.9297, 2.6562, 2.7344, 2.3594,\n",
       "         2.9062, 2.2969, 3.0469, 2.9531, 2.8281, 3.0625, 2.3438, 2.0000, 2.9219,\n",
       "         3.1875, 2.3906, 2.7344, 2.1719, 2.9219, 2.3906, 3.0469, 2.0938, 2.2031,\n",
       "         2.8906, 2.5156, 2.3125, 1.7734, 3.5156, 2.4688, 3.5000, 2.2969, 2.3750,\n",
       "         2.2188, 2.5625, 2.4375, 2.1250, 2.8750, 2.7031, 2.8594, 2.3125, 3.4531,\n",
       "         3.0938, 2.6094, 2.7656, 2.9062, 2.4375, 2.7031, 2.5781, 2.6094, 2.2812,\n",
       "         2.9375, 2.2031, 3.0156, 2.2812, 2.5625, 3.1406, 2.4062, 1.9062, 2.8438,\n",
       "         2.4375, 2.5156, 2.7031, 2.1406, 3.0469, 2.5469, 2.0469, 2.4062, 2.2344,\n",
       "         2.2188, 2.3594, 2.3438, 1.7656, 1.8984, 2.7656, 2.0938, 2.8125, 2.5625,\n",
       "         2.0781, 2.5312, 3.1562, 2.5000, 2.3438, 2.4062, 2.9375, 2.5312],\n",
       "        device='cuda:0'),\n",
       " 'blocksize': 64,\n",
       " 'quant_map': tensor([-1.0000, -0.6962, -0.5251, -0.3949, -0.2844, -0.1848, -0.0911,  0.0000,\n",
       "          0.0796,  0.1609,  0.2461,  0.3379,  0.4407,  0.5626,  0.7230,  1.0000],\n",
       "        device='cuda:0'),\n",
       " 'dtype': 'bfloat16',\n",
       " 'shape': (128, 256)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param.quant_state.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d82d89f-235e-4a2a-b0b3-62a3e5d2adbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size, output_size = data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea5b382e-e078-4a23-8a95-c5802eca1cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 256)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size, output_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a33876",
   "metadata": {},
   "source": [
    "### Column Parallel\n",
    "\n",
    "The linear layer is defined as Y = XA + b. A is parallelized along its second dimension as A = [A_1, ..., A_p]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54220b7c-a24b-4052-8ccc-d0cbe04827ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_partitions = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5883249c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qweight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec7d2b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_size_per_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8e60aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "qweight_partitioned = qweight.split(output_size_per_partition, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2f41ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qweight_partitioned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7746431f-166b-4a71-959c-83cead869e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 64])\n",
      "torch.Size([128, 64])\n"
     ]
    }
   ],
   "source": [
    "for w in qweight_partitioned: print(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be00bc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_absmax = param.quant_state.absmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5c02e37-8815-474e-8b2e-da1414790c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_absmax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3d776ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_absmax_reshaped = orig_absmax.reshape(input_size, data.size(1) // blocksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7e1670e-a677-47cc-9e67-1ea10d399e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.Size([128, 4]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_absmax_reshaped.dtype, orig_absmax_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dfd94e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_partitions = len(qweight_partitioned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f63f1e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "absmax_partitioned = orig_absmax_reshaped.split(orig_absmax_reshaped.size(1) // num_partitions, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d276291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 2])\n",
      "torch.Size([128, 2])\n"
     ]
    }
   ],
   "source": [
    "for a in absmax_partitioned: print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9e9668e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qweight_partitioned), len(absmax_partitioned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e7299d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_state = copy.deepcopy(param.quant_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "80b8bf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_state.shape = torch.Size([quant_state.shape[0], quant_state.shape[1]//num_partitions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "de428e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "241a2d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_state.absmax = absmax_partitioned[0].contiguous().view(-1)\n",
    "deqweight_part1 = dequantize_4bit(qweight_partitioned[0].contiguous().view(-1,1), quant_state=quant_state)\n",
    "\n",
    "quant_state.absmax = absmax_partitioned[1].contiguous().view(-1)\n",
    "deqweight_part2 = dequantize_4bit(qweight_partitioned[1].contiguous().view(-1,1), quant_state=quant_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e15c1671-03b7-45a4-b036-72bf3e82c43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 128]), torch.Size([128, 128]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deqweight_part1.shape, deqweight_part2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4085cb3-2b80-492a-b89b-ca259ce950c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# quant_state.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b63ec5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 256])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deqweight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "978e7a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 256])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([deqweight_part1, deqweight_part2], dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3d50215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.equal(deqweight, torch.cat([deqweight_part1, deqweight_part2], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a43bafd4-7b83-4314-9019-a41499be5045",
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = (x @ deqweight_part2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f2fe31f-1af2-4712-9356-b9894c2d7e35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out2 = bnb.matmul_4bit(x, qweight_partitioned[1].contiguous().view(-1,1), quant_state=quant_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1bf8b879-052b-48f4-ba5c-d28e1672d3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.equal(out1, out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "af60fb46-97b8-4b65-8f65-ddb11fd02c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc17f5f4",
   "metadata": {},
   "source": [
    "### Row Parallel\n",
    "\n",
    "The linear layer is defined as Y = XA + b. A is parallelized along\n",
    "its first dimension and X along its second dimension as:\n",
    "\n",
    "```\n",
    "    -   -\n",
    "    | A_1 |\n",
    "    | .   |\n",
    "A = | .   |        X = [X_1, ..., X_p]\n",
    "    | .   |\n",
    "    | A_p |\n",
    "    -   -\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8c3dc1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "qweight_partitioned = qweight.split(output_size_per_partition, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "98d0add2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_partitions = len(qweight_partitioned); num_partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "77c5bce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 128])\n",
      "torch.Size([64, 128])\n"
     ]
    }
   ],
   "source": [
    "for w in qweight_partitioned: print(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ed58848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_absmax = param.quant_state.absmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e368bab4-38d8-4ee5-9ca7-8a0943fd7de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_absmax_reshaped = orig_absmax.reshape(input_size, data.size(1) // blocksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1b155bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "absmax_partitioned = orig_absmax.split(len(orig_absmax) // num_partitions, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "130b5f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(absmax_partitioned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e64143be",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_state = copy.deepcopy(param.quant_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "47f91077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 256])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_state.shape = torch.Size([quant_state.shape[0]//num_partitions, quant_state.shape[1]]); quant_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "128e667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_state.absmax = absmax_partitioned[0].contiguous().view(-1)\n",
    "deqweight_part1 = dequantize_4bit(qweight_partitioned[0].contiguous().view(-1,1), quant_state=quant_state)\n",
    "\n",
    "quant_state.absmax = absmax_partitioned[1].contiguous().view(-1)\n",
    "deqweight_part2 = dequantize_4bit(qweight_partitioned[1].contiguous().view(-1,1), quant_state=quant_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d735c31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.equal(deqweight, torch.cat([deqweight_part1, deqweight_part2], dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b53f04e-f053-423b-b3f7-88283531858c",
   "metadata": {},
   "source": [
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b39e0da2-6d9e-4a0e-bec9-7e4007c8af09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 03-29 13:23:10 pynccl_utils.py:13] vLLM is using nccl==2.18.1\n"
     ]
    }
   ],
   "source": [
    "from vllm.model_executor.weight_utils import default_weight_loader, hf_model_weights_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b267b53-a7d4-43af-82e2-ac18b6b66a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_iterator = hf_model_weights_iterator(\"meta-llama/Llama-2-7b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cdc64de-22cd-413c-9b63-e2351e018c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 03-29 08:48:45 weight_utils.py:177] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd674cc5dcf7487f923f00c680e6a73e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93c344b17544540b2d5f59dac5af4c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, loaded_weight in weights_iterator: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0853623c-1c05-4599-8b74-26e55d33a310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('model.embed_tokens.weight',\n",
       " tensor([[ 1.2517e-06, -1.7881e-06, -4.3511e-06,  ...,  8.9407e-07,\n",
       "          -6.5565e-06,  8.9407e-07],\n",
       "         [ 1.8616e-03, -3.3722e-03,  3.9864e-04,  ..., -8.3008e-03,\n",
       "           2.5787e-03, -3.9368e-03],\n",
       "         [ 1.0986e-02,  9.8877e-03, -5.0964e-03,  ...,  2.5177e-03,\n",
       "           7.7057e-04, -5.0049e-03],\n",
       "         ...,\n",
       "         [-1.3977e-02, -2.7313e-03, -1.9897e-02,  ..., -1.0437e-02,\n",
       "           9.5825e-03, -1.8005e-03],\n",
       "         [-1.0742e-02,  9.3384e-03,  1.2939e-02,  ..., -3.3203e-02,\n",
       "          -1.6357e-02,  3.3875e-03],\n",
       "         [-8.3008e-03, -4.0588e-03, -1.1063e-03,  ...,  3.4790e-03,\n",
       "          -1.2939e-02,  3.1948e-05]], dtype=torch.float16))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name, loaded_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b31e4388-af56-49ee-b81e-a4d2a333bac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_iterator = hf_model_weights_iterator(\"TheBloke/CodeUp-Alpha-13B-HF-AWQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b23f97a-ad91-434b-aa63-2fa548c0193d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.0.mlp.down_proj.qzeros\n",
      "model.layers.0.mlp.down_proj.scales\n",
      "model.layers.0.mlp.gate_proj.qzeros\n",
      "model.layers.0.mlp.gate_proj.scales\n",
      "model.layers.0.mlp.up_proj.qzeros\n",
      "model.layers.0.mlp.up_proj.scales\n",
      "model.layers.0.self_attn.k_proj.qzeros\n",
      "model.layers.0.self_attn.k_proj.scales\n",
      "model.layers.0.self_attn.o_proj.qzeros\n",
      "model.layers.0.self_attn.o_proj.scales\n",
      "model.layers.0.self_attn.q_proj.qzeros\n",
      "model.layers.0.self_attn.q_proj.scales\n",
      "model.layers.0.self_attn.v_proj.qzeros\n",
      "model.layers.0.self_attn.v_proj.scales\n",
      "model.layers.1.mlp.down_proj.qzeros\n",
      "model.layers.1.mlp.down_proj.scales\n",
      "model.layers.1.mlp.gate_proj.qzeros\n",
      "model.layers.1.mlp.gate_proj.scales\n",
      "model.layers.1.mlp.up_proj.qzeros\n",
      "model.layers.1.mlp.up_proj.scales\n",
      "model.layers.1.self_attn.k_proj.qzeros\n",
      "model.layers.1.self_attn.k_proj.scales\n",
      "model.layers.1.self_attn.o_proj.qzeros\n",
      "model.layers.1.self_attn.o_proj.scales\n",
      "model.layers.1.self_attn.q_proj.qzeros\n",
      "model.layers.1.self_attn.q_proj.scales\n",
      "model.layers.1.self_attn.v_proj.qzeros\n",
      "model.layers.1.self_attn.v_proj.scales\n",
      "model.layers.10.mlp.down_proj.qzeros\n",
      "model.layers.10.mlp.down_proj.scales\n",
      "model.layers.10.mlp.gate_proj.qzeros\n",
      "model.layers.10.mlp.gate_proj.scales\n",
      "model.layers.10.mlp.up_proj.qzeros\n",
      "model.layers.10.mlp.up_proj.scales\n",
      "model.layers.10.self_attn.k_proj.qzeros\n",
      "model.layers.10.self_attn.k_proj.scales\n",
      "model.layers.10.self_attn.o_proj.qzeros\n",
      "model.layers.10.self_attn.o_proj.scales\n",
      "model.layers.10.self_attn.q_proj.qzeros\n",
      "model.layers.10.self_attn.q_proj.scales\n",
      "model.layers.10.self_attn.v_proj.qzeros\n",
      "model.layers.10.self_attn.v_proj.scales\n",
      "model.layers.11.mlp.down_proj.qzeros\n",
      "model.layers.11.mlp.down_proj.scales\n",
      "model.layers.11.mlp.gate_proj.qzeros\n",
      "model.layers.11.mlp.gate_proj.scales\n",
      "model.layers.11.mlp.up_proj.qzeros\n",
      "model.layers.11.mlp.up_proj.scales\n",
      "model.layers.11.self_attn.k_proj.qzeros\n",
      "model.layers.11.self_attn.k_proj.scales\n",
      "model.layers.11.self_attn.o_proj.qzeros\n",
      "model.layers.11.self_attn.o_proj.scales\n",
      "model.layers.11.self_attn.q_proj.qzeros\n",
      "model.layers.11.self_attn.q_proj.scales\n",
      "model.layers.11.self_attn.v_proj.qzeros\n",
      "model.layers.11.self_attn.v_proj.scales\n",
      "model.layers.12.mlp.down_proj.qzeros\n",
      "model.layers.12.mlp.down_proj.scales\n",
      "model.layers.12.mlp.gate_proj.qzeros\n",
      "model.layers.12.mlp.gate_proj.scales\n",
      "model.layers.12.mlp.up_proj.qzeros\n",
      "model.layers.12.mlp.up_proj.scales\n",
      "model.layers.12.self_attn.k_proj.qzeros\n",
      "model.layers.12.self_attn.k_proj.scales\n",
      "model.layers.12.self_attn.o_proj.qzeros\n",
      "model.layers.12.self_attn.o_proj.scales\n",
      "model.layers.12.self_attn.q_proj.qzeros\n",
      "model.layers.12.self_attn.q_proj.scales\n",
      "model.layers.12.self_attn.v_proj.qzeros\n",
      "model.layers.12.self_attn.v_proj.scales\n",
      "model.layers.13.mlp.down_proj.qzeros\n",
      "model.layers.13.mlp.down_proj.scales\n",
      "model.layers.13.mlp.gate_proj.qzeros\n",
      "model.layers.13.mlp.gate_proj.scales\n",
      "model.layers.13.mlp.up_proj.qzeros\n",
      "model.layers.13.mlp.up_proj.scales\n",
      "model.layers.13.self_attn.k_proj.qzeros\n",
      "model.layers.13.self_attn.k_proj.scales\n",
      "model.layers.13.self_attn.o_proj.qzeros\n",
      "model.layers.13.self_attn.o_proj.scales\n",
      "model.layers.13.self_attn.q_proj.qzeros\n",
      "model.layers.13.self_attn.q_proj.scales\n",
      "model.layers.13.self_attn.v_proj.qzeros\n",
      "model.layers.13.self_attn.v_proj.scales\n",
      "model.layers.14.mlp.down_proj.qzeros\n",
      "model.layers.14.mlp.down_proj.scales\n",
      "model.layers.14.mlp.gate_proj.qzeros\n",
      "model.layers.14.mlp.gate_proj.scales\n",
      "model.layers.14.mlp.up_proj.qzeros\n",
      "model.layers.14.mlp.up_proj.scales\n",
      "model.layers.14.self_attn.k_proj.qzeros\n",
      "model.layers.14.self_attn.k_proj.scales\n",
      "model.layers.14.self_attn.o_proj.qzeros\n",
      "model.layers.14.self_attn.o_proj.scales\n",
      "model.layers.14.self_attn.q_proj.qzeros\n",
      "model.layers.14.self_attn.q_proj.scales\n",
      "model.layers.14.self_attn.v_proj.qzeros\n",
      "model.layers.14.self_attn.v_proj.scales\n",
      "model.layers.15.mlp.down_proj.qzeros\n",
      "model.layers.15.mlp.down_proj.scales\n",
      "model.layers.15.mlp.gate_proj.qzeros\n",
      "model.layers.15.mlp.gate_proj.scales\n",
      "model.layers.15.mlp.up_proj.qzeros\n",
      "model.layers.15.mlp.up_proj.scales\n",
      "model.layers.15.self_attn.k_proj.qzeros\n",
      "model.layers.15.self_attn.k_proj.scales\n",
      "model.layers.15.self_attn.o_proj.qzeros\n",
      "model.layers.15.self_attn.o_proj.scales\n",
      "model.layers.15.self_attn.q_proj.qzeros\n",
      "model.layers.15.self_attn.q_proj.scales\n",
      "model.layers.15.self_attn.v_proj.qzeros\n",
      "model.layers.15.self_attn.v_proj.scales\n",
      "model.layers.16.mlp.down_proj.qzeros\n",
      "model.layers.16.mlp.down_proj.scales\n",
      "model.layers.16.mlp.gate_proj.qzeros\n",
      "model.layers.16.mlp.gate_proj.scales\n",
      "model.layers.16.mlp.up_proj.qzeros\n",
      "model.layers.16.mlp.up_proj.scales\n",
      "model.layers.16.self_attn.k_proj.qzeros\n",
      "model.layers.16.self_attn.k_proj.scales\n",
      "model.layers.16.self_attn.o_proj.qzeros\n",
      "model.layers.16.self_attn.o_proj.scales\n",
      "model.layers.16.self_attn.q_proj.qzeros\n",
      "model.layers.16.self_attn.q_proj.scales\n",
      "model.layers.16.self_attn.v_proj.qzeros\n",
      "model.layers.16.self_attn.v_proj.scales\n",
      "model.layers.17.mlp.down_proj.qzeros\n",
      "model.layers.17.mlp.down_proj.scales\n",
      "model.layers.17.mlp.gate_proj.qzeros\n",
      "model.layers.17.mlp.gate_proj.scales\n",
      "model.layers.17.mlp.up_proj.qzeros\n",
      "model.layers.17.mlp.up_proj.scales\n",
      "model.layers.17.self_attn.k_proj.qzeros\n",
      "model.layers.17.self_attn.k_proj.scales\n",
      "model.layers.17.self_attn.o_proj.qzeros\n",
      "model.layers.17.self_attn.o_proj.scales\n",
      "model.layers.17.self_attn.q_proj.qzeros\n",
      "model.layers.17.self_attn.q_proj.scales\n",
      "model.layers.17.self_attn.v_proj.qzeros\n",
      "model.layers.17.self_attn.v_proj.scales\n",
      "model.layers.18.mlp.down_proj.qzeros\n",
      "model.layers.18.mlp.down_proj.scales\n",
      "model.layers.18.mlp.gate_proj.qzeros\n",
      "model.layers.18.mlp.gate_proj.scales\n",
      "model.layers.18.mlp.up_proj.qzeros\n",
      "model.layers.18.mlp.up_proj.scales\n",
      "model.layers.18.self_attn.k_proj.qzeros\n",
      "model.layers.18.self_attn.k_proj.scales\n",
      "model.layers.18.self_attn.o_proj.qzeros\n",
      "model.layers.18.self_attn.o_proj.scales\n",
      "model.layers.18.self_attn.q_proj.qzeros\n",
      "model.layers.18.self_attn.q_proj.scales\n",
      "model.layers.18.self_attn.v_proj.qzeros\n",
      "model.layers.18.self_attn.v_proj.scales\n",
      "model.layers.19.mlp.down_proj.qzeros\n",
      "model.layers.19.mlp.down_proj.scales\n",
      "model.layers.19.mlp.gate_proj.qzeros\n",
      "model.layers.19.mlp.gate_proj.scales\n",
      "model.layers.19.mlp.up_proj.qzeros\n",
      "model.layers.19.mlp.up_proj.scales\n",
      "model.layers.19.self_attn.k_proj.qzeros\n",
      "model.layers.19.self_attn.k_proj.scales\n",
      "model.layers.19.self_attn.o_proj.qzeros\n",
      "model.layers.19.self_attn.o_proj.scales\n",
      "model.layers.19.self_attn.q_proj.qzeros\n",
      "model.layers.19.self_attn.q_proj.scales\n",
      "model.layers.19.self_attn.v_proj.qzeros\n",
      "model.layers.19.self_attn.v_proj.scales\n",
      "model.layers.2.mlp.down_proj.qzeros\n",
      "model.layers.2.mlp.down_proj.scales\n",
      "model.layers.2.mlp.gate_proj.qzeros\n",
      "model.layers.2.mlp.gate_proj.scales\n",
      "model.layers.2.mlp.up_proj.qzeros\n",
      "model.layers.2.mlp.up_proj.scales\n",
      "model.layers.2.self_attn.k_proj.qzeros\n",
      "model.layers.2.self_attn.k_proj.scales\n",
      "model.layers.2.self_attn.o_proj.qzeros\n",
      "model.layers.2.self_attn.o_proj.scales\n",
      "model.layers.2.self_attn.q_proj.qzeros\n",
      "model.layers.2.self_attn.q_proj.scales\n",
      "model.layers.2.self_attn.v_proj.qzeros\n",
      "model.layers.2.self_attn.v_proj.scales\n",
      "model.layers.20.mlp.down_proj.qzeros\n",
      "model.layers.20.mlp.down_proj.scales\n",
      "model.layers.20.mlp.gate_proj.qzeros\n",
      "model.layers.20.mlp.gate_proj.scales\n",
      "model.layers.20.mlp.up_proj.qzeros\n",
      "model.layers.20.mlp.up_proj.scales\n",
      "model.layers.20.self_attn.k_proj.qzeros\n",
      "model.layers.20.self_attn.k_proj.scales\n",
      "model.layers.20.self_attn.o_proj.qzeros\n",
      "model.layers.20.self_attn.o_proj.scales\n",
      "model.layers.20.self_attn.q_proj.qzeros\n",
      "model.layers.20.self_attn.q_proj.scales\n",
      "model.layers.20.self_attn.v_proj.qzeros\n",
      "model.layers.20.self_attn.v_proj.scales\n",
      "model.layers.21.mlp.down_proj.qzeros\n",
      "model.layers.21.mlp.down_proj.scales\n",
      "model.layers.21.mlp.gate_proj.qzeros\n",
      "model.layers.21.mlp.gate_proj.scales\n",
      "model.layers.21.mlp.up_proj.qzeros\n",
      "model.layers.21.mlp.up_proj.scales\n",
      "model.layers.21.self_attn.k_proj.qzeros\n",
      "model.layers.21.self_attn.k_proj.scales\n",
      "model.layers.21.self_attn.o_proj.qzeros\n",
      "model.layers.21.self_attn.o_proj.scales\n",
      "model.layers.21.self_attn.q_proj.qzeros\n",
      "model.layers.21.self_attn.q_proj.scales\n",
      "model.layers.21.self_attn.v_proj.qzeros\n",
      "model.layers.21.self_attn.v_proj.scales\n",
      "model.layers.22.mlp.down_proj.qzeros\n",
      "model.layers.22.mlp.down_proj.scales\n",
      "model.layers.22.mlp.gate_proj.qzeros\n",
      "model.layers.22.mlp.gate_proj.scales\n",
      "model.layers.22.mlp.up_proj.qzeros\n",
      "model.layers.22.mlp.up_proj.scales\n",
      "model.layers.22.self_attn.k_proj.qzeros\n",
      "model.layers.22.self_attn.k_proj.scales\n",
      "model.layers.22.self_attn.o_proj.qzeros\n",
      "model.layers.22.self_attn.o_proj.scales\n",
      "model.layers.22.self_attn.q_proj.qzeros\n",
      "model.layers.22.self_attn.q_proj.scales\n",
      "model.layers.22.self_attn.v_proj.qzeros\n",
      "model.layers.22.self_attn.v_proj.scales\n",
      "model.layers.23.mlp.down_proj.qzeros\n",
      "model.layers.23.mlp.down_proj.scales\n",
      "model.layers.23.mlp.gate_proj.qzeros\n",
      "model.layers.23.mlp.gate_proj.scales\n",
      "model.layers.23.mlp.up_proj.qzeros\n",
      "model.layers.23.mlp.up_proj.scales\n",
      "model.layers.23.self_attn.k_proj.qzeros\n",
      "model.layers.23.self_attn.k_proj.scales\n",
      "model.layers.23.self_attn.o_proj.qzeros\n",
      "model.layers.23.self_attn.o_proj.scales\n",
      "model.layers.23.self_attn.q_proj.qzeros\n",
      "model.layers.23.self_attn.q_proj.scales\n",
      "model.layers.23.self_attn.v_proj.qzeros\n",
      "model.layers.23.self_attn.v_proj.scales\n",
      "model.layers.24.mlp.down_proj.qzeros\n",
      "model.layers.24.mlp.down_proj.scales\n",
      "model.layers.24.mlp.gate_proj.qzeros\n",
      "model.layers.24.mlp.gate_proj.scales\n",
      "model.layers.24.mlp.up_proj.qzeros\n",
      "model.layers.24.mlp.up_proj.scales\n",
      "model.layers.24.self_attn.k_proj.qzeros\n",
      "model.layers.24.self_attn.k_proj.scales\n",
      "model.layers.24.self_attn.o_proj.qzeros\n",
      "model.layers.24.self_attn.o_proj.scales\n",
      "model.layers.24.self_attn.q_proj.qzeros\n",
      "model.layers.24.self_attn.q_proj.scales\n",
      "model.layers.24.self_attn.v_proj.qzeros\n",
      "model.layers.24.self_attn.v_proj.scales\n",
      "model.layers.25.mlp.down_proj.qzeros\n",
      "model.layers.25.mlp.down_proj.scales\n",
      "model.layers.25.mlp.gate_proj.qzeros\n",
      "model.layers.25.mlp.gate_proj.scales\n",
      "model.layers.25.mlp.up_proj.qzeros\n",
      "model.layers.25.mlp.up_proj.scales\n",
      "model.layers.25.self_attn.k_proj.qzeros\n",
      "model.layers.25.self_attn.k_proj.scales\n",
      "model.layers.25.self_attn.o_proj.qzeros\n",
      "model.layers.25.self_attn.o_proj.scales\n",
      "model.layers.25.self_attn.q_proj.qzeros\n",
      "model.layers.25.self_attn.q_proj.scales\n",
      "model.layers.25.self_attn.v_proj.qzeros\n",
      "model.layers.25.self_attn.v_proj.scales\n",
      "model.layers.26.mlp.down_proj.qzeros\n",
      "model.layers.26.mlp.down_proj.scales\n",
      "model.layers.26.mlp.gate_proj.qzeros\n",
      "model.layers.26.mlp.gate_proj.scales\n",
      "model.layers.26.mlp.up_proj.qzeros\n",
      "model.layers.26.mlp.up_proj.scales\n",
      "model.layers.26.self_attn.k_proj.qzeros\n",
      "model.layers.26.self_attn.k_proj.scales\n",
      "model.layers.26.self_attn.o_proj.qzeros\n",
      "model.layers.26.self_attn.o_proj.scales\n",
      "model.layers.26.self_attn.q_proj.qzeros\n",
      "model.layers.26.self_attn.q_proj.scales\n",
      "model.layers.26.self_attn.v_proj.qzeros\n",
      "model.layers.26.self_attn.v_proj.scales\n",
      "model.layers.27.mlp.down_proj.qzeros\n",
      "model.layers.27.mlp.down_proj.scales\n",
      "model.layers.27.mlp.gate_proj.qzeros\n",
      "model.layers.27.mlp.gate_proj.scales\n",
      "model.layers.27.mlp.up_proj.qzeros\n",
      "model.layers.27.mlp.up_proj.scales\n",
      "model.layers.27.self_attn.k_proj.qzeros\n",
      "model.layers.27.self_attn.k_proj.scales\n",
      "model.layers.27.self_attn.o_proj.qzeros\n",
      "model.layers.27.self_attn.o_proj.scales\n",
      "model.layers.27.self_attn.q_proj.qzeros\n",
      "model.layers.27.self_attn.q_proj.scales\n",
      "model.layers.27.self_attn.v_proj.qzeros\n",
      "model.layers.27.self_attn.v_proj.scales\n",
      "model.layers.28.mlp.down_proj.qzeros\n",
      "model.layers.28.mlp.down_proj.scales\n",
      "model.layers.28.mlp.gate_proj.qzeros\n",
      "model.layers.28.mlp.gate_proj.scales\n",
      "model.layers.28.mlp.up_proj.qzeros\n",
      "model.layers.28.mlp.up_proj.scales\n",
      "model.layers.28.self_attn.k_proj.qzeros\n",
      "model.layers.28.self_attn.k_proj.scales\n",
      "model.layers.28.self_attn.o_proj.qzeros\n",
      "model.layers.28.self_attn.o_proj.scales\n",
      "model.layers.28.self_attn.q_proj.qzeros\n",
      "model.layers.28.self_attn.q_proj.scales\n",
      "model.layers.28.self_attn.v_proj.qzeros\n",
      "model.layers.28.self_attn.v_proj.scales\n",
      "model.layers.29.mlp.down_proj.qzeros\n",
      "model.layers.29.mlp.down_proj.scales\n",
      "model.layers.29.mlp.gate_proj.qzeros\n",
      "model.layers.29.mlp.gate_proj.scales\n",
      "model.layers.29.mlp.up_proj.qzeros\n",
      "model.layers.29.mlp.up_proj.scales\n",
      "model.layers.29.self_attn.k_proj.qzeros\n",
      "model.layers.29.self_attn.k_proj.scales\n",
      "model.layers.29.self_attn.o_proj.qzeros\n",
      "model.layers.29.self_attn.o_proj.scales\n",
      "model.layers.29.self_attn.q_proj.qzeros\n",
      "model.layers.29.self_attn.q_proj.scales\n",
      "model.layers.29.self_attn.v_proj.qzeros\n",
      "model.layers.29.self_attn.v_proj.scales\n",
      "model.layers.3.mlp.down_proj.qzeros\n",
      "model.layers.3.mlp.down_proj.scales\n",
      "model.layers.3.mlp.gate_proj.qzeros\n",
      "model.layers.3.mlp.gate_proj.scales\n",
      "model.layers.3.mlp.up_proj.qzeros\n",
      "model.layers.3.mlp.up_proj.scales\n",
      "model.layers.3.self_attn.k_proj.qzeros\n",
      "model.layers.3.self_attn.k_proj.scales\n",
      "model.layers.3.self_attn.o_proj.qzeros\n",
      "model.layers.3.self_attn.o_proj.scales\n",
      "model.layers.3.self_attn.q_proj.qzeros\n",
      "model.layers.3.self_attn.q_proj.scales\n",
      "model.layers.3.self_attn.v_proj.qzeros\n",
      "model.layers.3.self_attn.v_proj.scales\n",
      "model.layers.30.mlp.down_proj.qzeros\n",
      "model.layers.30.mlp.down_proj.scales\n",
      "model.layers.30.mlp.gate_proj.qzeros\n",
      "model.layers.30.mlp.gate_proj.scales\n",
      "model.layers.30.mlp.up_proj.qzeros\n",
      "model.layers.30.mlp.up_proj.scales\n",
      "model.layers.30.self_attn.k_proj.qzeros\n",
      "model.layers.30.self_attn.k_proj.scales\n",
      "model.layers.30.self_attn.o_proj.qzeros\n",
      "model.layers.30.self_attn.o_proj.scales\n",
      "model.layers.30.self_attn.q_proj.qzeros\n",
      "model.layers.30.self_attn.q_proj.scales\n",
      "model.layers.30.self_attn.v_proj.qzeros\n",
      "model.layers.30.self_attn.v_proj.scales\n",
      "model.layers.31.mlp.down_proj.qzeros\n",
      "model.layers.31.mlp.down_proj.scales\n",
      "model.layers.31.mlp.gate_proj.qzeros\n",
      "model.layers.31.mlp.gate_proj.scales\n",
      "model.layers.31.mlp.up_proj.qzeros\n",
      "model.layers.31.mlp.up_proj.scales\n",
      "model.layers.31.self_attn.k_proj.qzeros\n",
      "model.layers.31.self_attn.k_proj.scales\n",
      "model.layers.31.self_attn.o_proj.qzeros\n",
      "model.layers.31.self_attn.o_proj.scales\n",
      "model.layers.31.self_attn.q_proj.qzeros\n",
      "model.layers.31.self_attn.q_proj.scales\n",
      "model.layers.31.self_attn.v_proj.qzeros\n",
      "model.layers.31.self_attn.v_proj.scales\n",
      "model.layers.32.mlp.down_proj.qzeros\n",
      "model.layers.32.mlp.down_proj.scales\n",
      "model.layers.32.mlp.gate_proj.qzeros\n",
      "model.layers.32.mlp.gate_proj.scales\n",
      "model.layers.32.mlp.up_proj.qzeros\n",
      "model.layers.32.mlp.up_proj.scales\n",
      "model.layers.32.self_attn.k_proj.qzeros\n",
      "model.layers.32.self_attn.k_proj.scales\n",
      "model.layers.32.self_attn.o_proj.qzeros\n",
      "model.layers.32.self_attn.o_proj.scales\n",
      "model.layers.32.self_attn.q_proj.qzeros\n",
      "model.layers.32.self_attn.q_proj.scales\n",
      "model.layers.32.self_attn.v_proj.qzeros\n",
      "model.layers.32.self_attn.v_proj.scales\n",
      "model.layers.33.mlp.down_proj.qzeros\n",
      "model.layers.33.mlp.down_proj.scales\n",
      "model.layers.33.mlp.gate_proj.qzeros\n",
      "model.layers.33.mlp.gate_proj.scales\n",
      "model.layers.33.mlp.up_proj.qzeros\n",
      "model.layers.33.mlp.up_proj.scales\n",
      "model.layers.33.self_attn.k_proj.qzeros\n",
      "model.layers.33.self_attn.k_proj.scales\n",
      "model.layers.33.self_attn.o_proj.qzeros\n",
      "model.layers.33.self_attn.o_proj.scales\n",
      "model.layers.33.self_attn.q_proj.qzeros\n",
      "model.layers.33.self_attn.q_proj.scales\n",
      "model.layers.33.self_attn.v_proj.qzeros\n",
      "model.layers.33.self_attn.v_proj.scales\n",
      "model.layers.34.mlp.down_proj.qzeros\n",
      "model.layers.34.mlp.down_proj.scales\n",
      "model.layers.34.mlp.gate_proj.qzeros\n",
      "model.layers.34.mlp.gate_proj.scales\n",
      "model.layers.34.mlp.up_proj.qzeros\n",
      "model.layers.34.mlp.up_proj.scales\n",
      "model.layers.34.self_attn.k_proj.qzeros\n",
      "model.layers.34.self_attn.k_proj.scales\n",
      "model.layers.34.self_attn.o_proj.qzeros\n",
      "model.layers.34.self_attn.o_proj.scales\n",
      "model.layers.34.self_attn.q_proj.qzeros\n",
      "model.layers.34.self_attn.q_proj.scales\n",
      "model.layers.34.self_attn.v_proj.qzeros\n",
      "model.layers.34.self_attn.v_proj.scales\n",
      "model.layers.35.mlp.down_proj.qzeros\n",
      "model.layers.35.mlp.down_proj.scales\n",
      "model.layers.35.mlp.gate_proj.qzeros\n",
      "model.layers.35.mlp.gate_proj.scales\n",
      "model.layers.35.mlp.up_proj.qzeros\n",
      "model.layers.35.mlp.up_proj.scales\n",
      "model.layers.35.self_attn.k_proj.qzeros\n",
      "model.layers.35.self_attn.k_proj.scales\n",
      "model.layers.35.self_attn.o_proj.qzeros\n",
      "model.layers.35.self_attn.o_proj.scales\n",
      "model.layers.35.self_attn.q_proj.qzeros\n",
      "model.layers.35.self_attn.q_proj.scales\n",
      "model.layers.35.self_attn.v_proj.qzeros\n",
      "model.layers.35.self_attn.v_proj.scales\n",
      "model.layers.36.mlp.down_proj.qzeros\n",
      "model.layers.36.mlp.down_proj.scales\n",
      "model.layers.36.mlp.gate_proj.qzeros\n",
      "model.layers.36.mlp.gate_proj.scales\n",
      "model.layers.36.mlp.up_proj.qzeros\n",
      "model.layers.36.mlp.up_proj.scales\n",
      "model.layers.36.self_attn.k_proj.qzeros\n",
      "model.layers.36.self_attn.k_proj.scales\n",
      "model.layers.36.self_attn.o_proj.qzeros\n",
      "model.layers.36.self_attn.o_proj.scales\n",
      "model.layers.36.self_attn.q_proj.qzeros\n",
      "model.layers.36.self_attn.q_proj.scales\n",
      "model.layers.36.self_attn.v_proj.qzeros\n",
      "model.layers.36.self_attn.v_proj.scales\n",
      "model.layers.37.mlp.down_proj.qzeros\n",
      "model.layers.37.mlp.down_proj.scales\n",
      "model.layers.37.mlp.gate_proj.qzeros\n",
      "model.layers.37.mlp.gate_proj.scales\n",
      "model.layers.37.mlp.up_proj.qzeros\n",
      "model.layers.37.mlp.up_proj.scales\n",
      "model.layers.37.self_attn.k_proj.qzeros\n",
      "model.layers.37.self_attn.k_proj.scales\n",
      "model.layers.37.self_attn.o_proj.qzeros\n",
      "model.layers.37.self_attn.o_proj.scales\n",
      "model.layers.37.self_attn.q_proj.qzeros\n",
      "model.layers.37.self_attn.q_proj.scales\n",
      "model.layers.37.self_attn.v_proj.qzeros\n",
      "model.layers.37.self_attn.v_proj.scales\n",
      "model.layers.38.mlp.down_proj.qzeros\n",
      "model.layers.38.mlp.down_proj.scales\n",
      "model.layers.38.mlp.gate_proj.qzeros\n",
      "model.layers.38.mlp.gate_proj.scales\n",
      "model.layers.38.mlp.up_proj.qzeros\n",
      "model.layers.38.mlp.up_proj.scales\n",
      "model.layers.38.self_attn.k_proj.qzeros\n",
      "model.layers.38.self_attn.k_proj.scales\n",
      "model.layers.38.self_attn.o_proj.qzeros\n",
      "model.layers.38.self_attn.o_proj.scales\n",
      "model.layers.38.self_attn.q_proj.qzeros\n",
      "model.layers.38.self_attn.q_proj.scales\n",
      "model.layers.38.self_attn.v_proj.qzeros\n",
      "model.layers.38.self_attn.v_proj.scales\n",
      "model.layers.39.mlp.down_proj.qzeros\n",
      "model.layers.39.mlp.down_proj.scales\n",
      "model.layers.39.mlp.gate_proj.qzeros\n",
      "model.layers.39.mlp.gate_proj.scales\n",
      "model.layers.39.mlp.up_proj.qzeros\n",
      "model.layers.39.mlp.up_proj.scales\n",
      "model.layers.39.self_attn.k_proj.qzeros\n",
      "model.layers.39.self_attn.k_proj.scales\n",
      "model.layers.39.self_attn.o_proj.qzeros\n",
      "model.layers.39.self_attn.o_proj.scales\n",
      "model.layers.39.self_attn.q_proj.qzeros\n",
      "model.layers.39.self_attn.q_proj.scales\n",
      "model.layers.39.self_attn.v_proj.qzeros\n",
      "model.layers.39.self_attn.v_proj.scales\n",
      "model.layers.4.mlp.down_proj.qzeros\n",
      "model.layers.4.mlp.down_proj.scales\n",
      "model.layers.4.mlp.gate_proj.qzeros\n",
      "model.layers.4.mlp.gate_proj.scales\n",
      "model.layers.4.mlp.up_proj.qzeros\n",
      "model.layers.4.mlp.up_proj.scales\n",
      "model.layers.4.self_attn.k_proj.qzeros\n",
      "model.layers.4.self_attn.k_proj.scales\n",
      "model.layers.4.self_attn.o_proj.qzeros\n",
      "model.layers.4.self_attn.o_proj.scales\n",
      "model.layers.4.self_attn.q_proj.qzeros\n",
      "model.layers.4.self_attn.q_proj.scales\n",
      "model.layers.4.self_attn.v_proj.qzeros\n",
      "model.layers.4.self_attn.v_proj.scales\n",
      "model.layers.5.mlp.down_proj.qzeros\n",
      "model.layers.5.mlp.down_proj.scales\n",
      "model.layers.5.mlp.gate_proj.qzeros\n",
      "model.layers.5.mlp.gate_proj.scales\n",
      "model.layers.5.mlp.up_proj.qzeros\n",
      "model.layers.5.mlp.up_proj.scales\n",
      "model.layers.5.self_attn.k_proj.qzeros\n",
      "model.layers.5.self_attn.k_proj.scales\n",
      "model.layers.5.self_attn.o_proj.qzeros\n",
      "model.layers.5.self_attn.o_proj.scales\n",
      "model.layers.5.self_attn.q_proj.qzeros\n",
      "model.layers.5.self_attn.q_proj.scales\n",
      "model.layers.5.self_attn.v_proj.qzeros\n",
      "model.layers.5.self_attn.v_proj.scales\n",
      "model.layers.6.mlp.down_proj.qzeros\n",
      "model.layers.6.mlp.down_proj.scales\n",
      "model.layers.6.mlp.gate_proj.qzeros\n",
      "model.layers.6.mlp.gate_proj.scales\n",
      "model.layers.6.mlp.up_proj.qzeros\n",
      "model.layers.6.mlp.up_proj.scales\n",
      "model.layers.6.self_attn.k_proj.qzeros\n",
      "model.layers.6.self_attn.k_proj.scales\n",
      "model.layers.6.self_attn.o_proj.qzeros\n",
      "model.layers.6.self_attn.o_proj.scales\n",
      "model.layers.6.self_attn.q_proj.qzeros\n",
      "model.layers.6.self_attn.q_proj.scales\n",
      "model.layers.6.self_attn.v_proj.qzeros\n",
      "model.layers.6.self_attn.v_proj.scales\n",
      "model.layers.7.mlp.down_proj.qzeros\n",
      "model.layers.7.mlp.down_proj.scales\n",
      "model.layers.7.mlp.gate_proj.qzeros\n",
      "model.layers.7.mlp.gate_proj.scales\n",
      "model.layers.7.mlp.up_proj.qzeros\n",
      "model.layers.7.mlp.up_proj.scales\n",
      "model.layers.7.self_attn.k_proj.qzeros\n",
      "model.layers.7.self_attn.k_proj.scales\n",
      "model.layers.7.self_attn.o_proj.qzeros\n",
      "model.layers.7.self_attn.o_proj.scales\n",
      "model.layers.7.self_attn.q_proj.qzeros\n",
      "model.layers.7.self_attn.q_proj.scales\n",
      "model.layers.7.self_attn.v_proj.qzeros\n",
      "model.layers.7.self_attn.v_proj.scales\n",
      "model.layers.8.mlp.down_proj.qzeros\n",
      "model.layers.8.mlp.down_proj.scales\n",
      "model.layers.8.mlp.gate_proj.qzeros\n",
      "model.layers.8.mlp.gate_proj.scales\n",
      "model.layers.8.mlp.up_proj.qzeros\n",
      "model.layers.8.mlp.up_proj.scales\n",
      "model.layers.8.self_attn.k_proj.qzeros\n",
      "model.layers.8.self_attn.k_proj.scales\n",
      "model.layers.8.self_attn.o_proj.qzeros\n",
      "model.layers.8.self_attn.o_proj.scales\n",
      "model.layers.8.self_attn.q_proj.qzeros\n",
      "model.layers.8.self_attn.q_proj.scales\n",
      "model.layers.8.self_attn.v_proj.qzeros\n",
      "model.layers.8.self_attn.v_proj.scales\n",
      "model.layers.9.mlp.down_proj.qzeros\n",
      "model.layers.9.mlp.down_proj.scales\n",
      "model.layers.9.mlp.gate_proj.qzeros\n",
      "model.layers.9.mlp.gate_proj.scales\n",
      "model.layers.9.mlp.up_proj.qzeros\n",
      "model.layers.9.mlp.up_proj.scales\n",
      "model.layers.9.self_attn.k_proj.qzeros\n",
      "model.layers.9.self_attn.k_proj.scales\n",
      "model.layers.9.self_attn.o_proj.qzeros\n",
      "model.layers.9.self_attn.o_proj.scales\n",
      "model.layers.9.self_attn.q_proj.qzeros\n",
      "model.layers.9.self_attn.q_proj.scales\n",
      "model.layers.9.self_attn.v_proj.qzeros\n",
      "model.layers.9.self_attn.v_proj.scales\n"
     ]
    }
   ],
   "source": [
    "for name, loaded_weight in weights_iterator: \n",
    "    if 'scales' in name or 'zeros' in name:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9098d1-2374-4060-b8fe-60052c04110e",
   "metadata": {},
   "source": [
    "### Create Quantized Model Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e7cfc1da-2147-4722-a766-ee216a29ff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, json\n",
    "from safetensors.torch import save_file\n",
    "import copy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c7d1dd78-d696-4477-b878-a13a763c270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = Path(\"/home/ubuntu/models/llama-7b-orca-math-100k-full-quantized\")\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "714a8cb2-6eff-4645-bcff-c4bf66238802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original quantized layers from fsdp_qlora/train.py\n",
    "# [\"k_proj\", \"q_proj\", \"v_proj\", \"up_proj\", \"down_proj\", \"gate_proj\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "afaa582c-95b9-4e22-a209-485cfb73f129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to AWQ for now\n",
    "quantized_layers = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "65b4afb3-d1ff-434d-8e8d-e9537b1ccda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "orca_math_model_dir = \"/home/ubuntu/models/llama-7b-orca-math-100k-full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4e3067be-c874-4550-b999-1452d7e8f938",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = safetensors.torch.load_file(glob(os.path.join(orca_math_model_dir, \"*.safetensors\"))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9eaef503-678f-4084-b3f7-faa0af7f6d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_state_dict = copy.deepcopy(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a3686d0a-497a-4486-bf84-169dc6924ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pack_factor = 2\n",
    "blocksize = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7c23baa0-6dc7-4939-986d-9bf0e6b2722a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.0.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.0.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.0.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.0.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.0.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.0.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.0.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.1.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.1.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.1.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.1.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.1.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.1.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.1.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.10.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.10.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.10.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.10.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.10.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.10.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.10.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.11.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.11.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.11.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.11.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.11.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.11.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.11.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.12.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.12.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.12.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.12.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.12.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.12.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.12.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.13.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.13.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.13.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.13.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.13.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.13.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.13.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.14.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.14.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.14.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.14.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.14.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.14.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.14.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.15.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.15.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.15.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.15.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.15.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.15.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.15.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.16.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.16.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.16.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.16.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.16.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.16.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.16.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.17.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.17.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.17.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.17.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.17.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.17.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.17.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.18.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.18.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.18.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.18.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.18.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.18.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.18.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.19.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.19.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.19.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.19.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.19.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.19.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.19.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.2.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.2.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.2.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.2.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.2.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.2.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.2.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.20.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.20.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.20.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.20.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.20.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.20.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.20.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.21.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.21.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.21.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.21.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.21.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.21.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.21.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.22.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.22.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.22.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.22.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.22.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.22.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.22.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.23.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.23.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.23.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.23.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.23.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.23.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.23.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.24.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.24.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.24.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.24.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.24.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.24.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.24.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.25.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.25.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.25.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.25.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.25.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.25.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.25.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.26.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.26.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.26.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.26.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.26.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.26.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.26.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.27.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.27.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.27.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.27.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.27.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.27.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.27.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.28.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.28.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.28.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.28.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.28.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.28.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.28.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.29.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.29.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.29.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.29.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.29.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.29.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.29.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.3.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.3.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.3.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.3.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.3.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.3.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.3.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.30.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.30.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.30.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.30.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.30.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.30.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.30.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.31.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.31.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.31.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.31.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.31.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.31.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.31.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.4.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.4.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.4.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.4.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.4.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.4.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.4.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.5.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.5.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.5.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.5.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.5.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.5.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.5.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.6.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.6.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.6.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.6.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.6.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.6.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.6.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.7.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.7.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.7.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.7.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.7.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.7.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.7.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.8.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.8.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.8.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.8.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.8.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.8.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.8.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.9.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.9.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.9.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.9.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.9.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.9.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.9.self_attn.v_proj.weight torch.Size([4096, 4096])\n"
     ]
    }
   ],
   "source": [
    "for n,p in iter(weights.items()):\n",
    "    if any(l in n for l in quantized_layers) and \"weight\" in n:\n",
    "        # output_size x input_size\n",
    "        print(n, p.shape)\n",
    "        input_size, output_size = p.shape\n",
    "        param = Params4bit(p, quant_type=\"nf4\", blocksize=blocksize, compress_statistics=False, quant_storage=torch.uint8)\n",
    "        param.cuda();\n",
    "\n",
    "        # reshape for tensor parallelism\n",
    "        qweight, absmax = param.data.cpu(), param.quant_state.absmax.cpu()        \n",
    "        qweight = qweight.reshape(input_size, output_size // pack_factor)\n",
    "        absmax = absmax.reshape(input_size, output_size // blocksize)\n",
    "                \n",
    "        quantized_state_dict[n] = qweight\n",
    "        quantized_state_dict[n.replace(\".weight\", \".absmax\")] = absmax\n",
    "\n",
    "        param = None\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "07d917df-7614-41b5-bac7-c85fb73c9ef3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save quantized weights\n",
    "save_file(quantized_state_dict, model_dir/\"model_state_dict.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3c27a023-7ef7-456f-a3e9-d40c453b60cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save quant config\n",
    "quant_config_dict = {\n",
    "    \"weight_bits\" : 4,\n",
    "    \"blocksize\" : 64,\n",
    "    \"quant_type\" : \"nf4\",\n",
    "    \"quant_storage\" : \"uint8\",\n",
    "    \"compress_statistics\" : False\n",
    "}\n",
    "quant_config_filename = model_dir/\"quantize_config.json\"\n",
    "with open(quant_config_filename, \"w+\") as f: json.dump(quant_config_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4254ffdf-8b6e-47da-ae80-27f9e19f4b06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save model config\n",
    "model_config = AutoConfig.from_pretrained(\"meta-llama/Llama-2-7b-hf\")\n",
    "model_config_filename = model_dir/\"config.json\"\n",
    "with open(model_config_filename, \"w+\") as f: json.dump(model_config.to_dict(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a28ac0-9d96-46a6-a0e8-a28211728cb4",
   "metadata": {},
   "source": [
    "### BNB Quantized VLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81f8c396-e4ec-4bc5-81b0-0bf7239a73ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import hf_hub_download\n",
    "# import os\n",
    "# os.makedirs(\"/home/ubuntu/models/llama-7b-orca-math-100k-full\", exist_ok=True)\n",
    "# hf_hub_download(repo_id=\"answerdotai/llama-7b-orca-math-100k-full\", \n",
    "#                 filename=\"model_state_dict.safetensors\",\n",
    "#                 local_dir=\"/home/ubuntu/models/llama-7b-orca-math-100k-full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4eca361-0895-4858-ad46-c705ff64451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import List\n",
    "import safetensors\n",
    "import safetensors.torch\n",
    "from pathlib import Path\n",
    "import bitsandbytes as bnb\n",
    "from bitsandbytes.functional import dequantize_4bit, QuantState\n",
    "from bitsandbytes.nn.modules import Params4bit, Linear4bit\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\n",
    "from transformers.generation.configuration_utils import GenerationConfig\n",
    "from accelerate import init_empty_weights\n",
    "from glob import glob\n",
    "import os\n",
    "from fastcore.parallel import parallel\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c98b3fff-f6ad-488b-b41a-0f108bb7688b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f053d9b4-a087-4301-b069-def8705ec4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm.sequence import SequenceGroupMetadata, SequenceData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5951483a-d5d6-4c82-bab0-c07d868f8c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c61c1c1c-6717-42d7-870f-713b4923bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_linear(model:nn.Module, linear_replacement:nn.Module, quant_config:dict|None=None,\n",
    "                   skip_modules:List[str]=[\"lm_head\"], **kwargs):\n",
    "    \"\"\"\n",
    "    Replace linear modules with a new Linear module.\n",
    "    Parameters:\n",
    "        model (`torch.nn.Module`):\n",
    "            Input model or `torch.nn.Module` as the function is run recursively.\n",
    "        linear_replacement (`torch.nn.Module`):\n",
    "            The linear module that replaces the old one. Only expects standard arguments.\n",
    "            If other arguments need to be passed, use a lambda.\n",
    "        skip_modules (`List[str]`, *optional*, defaults to `lm_head`):\n",
    "            List of modules names not to convert. Defaults to `lm_head`.\n",
    "    \"\"\"\n",
    "    for name, module in model.named_children():\n",
    "        if name in skip_modules:\n",
    "            print(f\"Skipping {name}\")\n",
    "            continue\n",
    "        \n",
    "        if len(list(module.children())) > 0:\n",
    "            replace_linear(module, linear_replacement, quant_config, skip_modules, **kwargs)\n",
    "\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            if issubclass(linear_replacement, Linear4bit):\n",
    "                model._modules[name] = linear_replacement(\n",
    "                    module.in_features,\n",
    "                    module.out_features,\n",
    "                    module.bias is not None,\n",
    "                    **kwargs\n",
    "                )\n",
    "            # elif issubclass(linear_replacement, HQQLinear):\n",
    "            #     model._modules[name] = linear_replacement(module, quant_config, **kwargs)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported linear replacement: {type(linear_replacement)}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd8402bd-a3b6-4479-8ab3-21fb9c8c8ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_quantize(module:nn.Module, name:str, value:torch.Tensor, device:torch.device=None, dtype:torch.dtype=None,\n",
    "                      skip_names:list[str]=[], is_meta_rank:bool=False, low_memory:bool=True, verbose:bool=False,\n",
    "                      quant_method:str='bnb', is_dora:bool=False):\n",
    "    \"\"\"\n",
    "    Loads `value` tensor into submodule of `module`, optionally skipping `skip_names` and converting to `dtype`.\n",
    "\n",
    "    Quantizes `Params4bit` on `device` then places on \"cpu\" if low_memory=True or \"meta\" if is_meta_rank=True.\n",
    "    \"\"\"\n",
    "    def place_on_device(value):\n",
    "        if is_meta_rank:\n",
    "            device = 'meta'\n",
    "        elif low_memory:\n",
    "            device = 'cpu'\n",
    "        return value.to(device=device, dtype=dtype)\n",
    "\n",
    "    if any([skip_name in name for skip_name in skip_names]):\n",
    "        if verbose:\n",
    "            print(f\"Skipping {name} because it is in skip_names\")\n",
    "        return\n",
    "\n",
    "    module_key, _, value_key = name.rpartition('.')\n",
    "    try:\n",
    "        submodule = module.get_submodule(module_key)\n",
    "    except AttributeError as e:\n",
    "        print(f\"Module {module_key} not found:\\n{e}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        if quant_method=='bnb':\n",
    "            param = submodule.get_parameter(value_key)\n",
    "            if isinstance(param, Params4bit):\n",
    "                # With `sync_module_states=True`, a meta device Params4bit needs to be the same\n",
    "                # shape as the quantized Params4bit with an initialized quant_state. However,\n",
    "                # FSDP only syncs parameters and buffers, so the quant_state isn't copied. This\n",
    "                # workaround quantizes Params4bit to initialize quant_state on all ranks, then\n",
    "                # replaces Params4bit's data with a meta tensor to free memory on non-rank 0.\n",
    "                if is_dora:\n",
    "                    setattr(submodule, \"dora_scale\", value.norm(p=2, dim=1).to(dtype=dtype).to(\"cpu\"))                \n",
    "                    print(\"DORA scale initialized\")\n",
    "                value = type(param)(value.to(device=device, dtype=dtype).data, **param.__dict__).cuda(device)\n",
    "                if is_meta_rank:\n",
    "                    value = type(param)(value.data.to(\"meta\"), **value.__dict__)\n",
    "                elif low_memory:\n",
    "                    value = type(param)(value.data.to(\"cpu\"), **value.__dict__)\n",
    "                # print(\"Loaded quantized layer\")\n",
    "            else:\n",
    "                value = type(param)(place_on_device(value).data)\n",
    "                # print(\"Loaded regular layer\")\n",
    "    except AttributeError:\n",
    "        # it's a buffer\n",
    "        value = place_on_device(value)\n",
    "        pass\n",
    "    setattr(submodule, value_key, value)\n",
    "\n",
    "def load_and_quantize_parallel(name_param, model, **kwargs):\n",
    "    name, param = name_param\n",
    "    load_and_quantize(model, name, param, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c859ec51-9ea5-462f-a01e-afbe15fb3e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "orca_math_model_dir = \"/home/ubuntu/models/llama-7b-orca-math-100k-full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "815e7ff7-55e5-4f2f-90e7-65a35cf1a289",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"meta-llama/Llama-2-7b-hf\"\n",
    "cfg = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "cfg._attn_implementation = \"sdpa\"\n",
    "skip_modules = [\"lm_head\"]\n",
    "load_param_skip_names = ['inv_freq']\n",
    "compute_dtype = torch_dtype = torch.bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adcd81a1-ee01-4e43-9f27-e0647a536a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with init_empty_weights():\n",
    "    model = AutoModelForCausalLM.from_config(cfg)\n",
    "    model.model = replace_linear(model.model, Linear4bit, compute_dtype=compute_dtype,\n",
    "                                 quant_type='nf4', compress_statistics=False,\n",
    "                                 quant_storage=torch.uint8, skip_modules=skip_modules)\n",
    "model.is_loaded_in_4bit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a7d4b70-42b2-4ee3-9afd-feb4193f75a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = safetensors.torch.load_file(glob(os.path.join(orca_math_model_dir, \"*.safetensors\"))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d13a7fef-3cc5-4c8a-93e6-80c4c8ee2b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#291) [None,None,None,None,None,None,None,None,None,None...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel(load_and_quantize_parallel, \n",
    "         iter(weights.items()), \n",
    "         n_workers=8, \n",
    "         threadpool=True,\n",
    "         model=model, \n",
    "         dtype=torch_dtype, \n",
    "         device=torch.cuda.current_device(),\n",
    "         skip_names=load_param_skip_names,\n",
    "         is_meta_rank=False,\n",
    "         verbose=True,\n",
    "         quant_method=\"bnb\",\n",
    "         is_dora=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea38000d-dcc5-41da-bb24-386cefcfd954",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dc23e20-ae9e-4a2c-98cd-b7195bdd1b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\")\n",
    "hf_tokenizer.pad_token_id = hf_tokenizer.unk_token_id\n",
    "hf_tokenizer.pad_token = hf_tokenizer.unk_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb62eb87-228d-4269-aa03-3710b5db3ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bed4abb8-d7ee-4417-ae26-d41be9df0462",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"\"\"###Question:\n",
    "A certain tax rate is some amount per $100.00. The rate, expressed as a percent, is 65%. What is the tax rate in dollars per $100.00?\n",
    "###Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f421631-8499-4d9c-8398-9a92c48c15ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> ###Question:\n",
      "A certain tax rate is some amount per $100.00. The rate, expressed as a percent, is 65%. What is the tax rate in dollars per $100.00?\n",
      "###Answer:\n",
      "To find the tax rate in dollars per $100.00\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(hf_tokenizer(input, return_tensors=\"pt\")['input_ids'].cuda(),\n",
    "                        generation_config=GenerationConfig(do_sample=False, max_new_tokens=16, use_cache=True, \n",
    "                                                           pad_token_id=hf_tokenizer.pad_token_id)).cpu()\n",
    "print(hf_tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d77d66c6-3eb0-42fa-b6e2-a4df44db6010",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 04-04 12:12:41 config.py:744] Casting torch.float16 to torch.bfloat16.\n",
      "WARNING 04-04 12:12:41 config.py:208] bnb quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n",
      "INFO 04-04 12:12:41 llm_engine.py:70] Initializing an LLM engine (v0.3.3) with config: model='/home/ubuntu/models/llama-7b-orca-math-100k-full-quantized', tokenizer='meta-llama/Llama-2-7b-hf', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=bnb, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=0)\n",
      "INFO 04-04 12:12:41 pynccl_utils.py:13] vLLM is using nccl==2.18.1\n",
      "INFO 04-04 12:12:41 selector.py:15] Using FlashAttention backend.\n",
      "INFO 04-04 12:12:44 model_runner.py:104] Loading model weights took 3.9292 GB\n",
      "INFO 04-04 12:12:45 gpu_executor.py:94] # GPU blocks: 897, # CPU blocks: 512\n",
      "INFO 04-04 12:12:47 model_runner.py:770] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 04-04 12:12:47 model_runner.py:774] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 04-04 12:12:57 model_runner.py:846] Graph capturing finished in 9 secs.\n",
      "INFO 04-04 12:12:57 block_manager_v1.py:239] disable automatic prefix caching\n"
     ]
    }
   ],
   "source": [
    "orca_math_model_dir = \"/home/ubuntu/models/llama-7b-orca-math-100k-full-quantized\"\n",
    "llm = LLM(model=orca_math_model_dir, tokenizer=\"meta-llama/Llama-2-7b-hf\", dtype=\"bfloat16\",\n",
    "          quantization=\"bnb\", gpu_memory_utilization=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec4a0ddd-d2b4-4fa8-8eca-64e363a2a57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RequestOutput(request_id=0, prompt='###Question:\\nA certain tax rate is some amount per $100.00. The rate, expressed as a percent, is 65%. What is the tax rate in dollars per $100.00?\\n###Answer:', prompt_token_ids=[1, 835, 16492, 29901, 13, 29909, 3058, 8818, 6554, 338, 777, 5253, 639, 395, 29896, 29900, 29900, 29889, 29900, 29900, 29889, 450, 6554, 29892, 13384, 408, 263, 10151, 29892, 338, 29871, 29953, 29945, 15543, 1724, 338, 278, 8818, 6554, 297, 17208, 639, 395, 29896, 29900, 29900, 29889, 29900, 29900, 29973, 13, 2277, 29937, 22550, 29901], prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='\\n Cat Abs Abs Abs Cat Cat Cat Cat Cat Cat Cat Cat Cat Cat Cat', token_ids=[13, 10459, 24650, 24650, 24650, 10459, 10459, 10459, 10459, 10459, 10459, 10459, 10459, 10459, 10459, 10459], cumulative_logprob=-60.78300518193282, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1712232777.2982388, last_token_time=1712232777.2982388, first_scheduled_time=1712232777.3024695, first_token_time=1712232777.3649642, time_in_queue=0.0042307376861572266, finished_time=1712232777.6651087), lora_request=None)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab010da7-0afb-4312-87ef-791b92e9e068",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###Question:\n",
      "A certain tax rate is some amount per $100.00. The rate, expressed as a percent, is 65%. What is the tax rate in dollars per $100.00?\n",
      "###Answer:\n",
      " Cat Abs Abs Abs Cat Cat Cat Cat Cat Cat Cat Cat Cat Cat Cat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = llm.generate([input], sampling_params=SamplingParams(max_tokens=16, temperature=0.))\n",
    "print(input + outputs[0].outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "877f7f30-d42a-4a7e-b6ff-625615f48bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vllm_model = llm.llm_engine.model_executor.driver_worker.model_runner.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53e9af6f-36d1-4557-b491-1769779c1cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_layers = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35c37141-98b8-4f9b-8745-5b2d4841f944",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for n,p in model.named_parameters():\n",
    "#     # if \"qkv\" in n: break # quantized layers are not casted to dtype, which is correct.\n",
    "#     # if \"lm_head\" in n: break\n",
    "#     if any(l in n for l in quantized_layers):\n",
    "#         print(n, p.dtype)\n",
    "#         # assert p.dtype == torch.uint8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0f1544-42d8-4707-abfd-4a9f5a27f5e9",
   "metadata": {},
   "source": [
    "#### Compare QKV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ff0fe7a-0de8-4816-bf51-148dd5b62ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "550ebc16-b1e6-4df9-bcec-5c02869b330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = model.get_submodule(f'model.layers.{layer}.self_attn.q_proj')\n",
    "k = model.get_submodule(f'model.layers.{layer}.self_attn.k_proj')\n",
    "v = model.get_submodule(f'model.layers.{layer}.self_attn.v_proj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7b2b75d-e838-4140-a24a-d250bba82acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qkv = vllm_model.get_submodule(f'model.layers.{layer}.self_attn.qkv_proj')\n",
    "\n",
    "# assert torch.equal(q.weight, qkv.weight.split(4096, dim=0)[0].reshape(-1,1))\n",
    "# assert torch.equal(k.weight, qkv.weight.split(4096, dim=0)[1].reshape(-1,1))\n",
    "# assert torch.equal(v.weight, qkv.weight.split(4096, dim=0)[2].reshape(-1,1))\n",
    "\n",
    "# assert torch.equal(q.quant_state.absmax, qkv.absmax.view(-1).split(4096*4096//64)[0])\n",
    "# assert torch.equal(k.quant_state.absmax, qkv.absmax.view(-1).split(4096*4096//64)[1])\n",
    "# assert torch.equal(v.quant_state.absmax, qkv.absmax.view(-1).split(4096*4096//64)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7bd77a07-aa1c-40b6-aac0-532927e7d85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2 = vllm_model.get_submodule(f'model.layers.{layer}.self_attn.q_proj')\n",
    "k2 = vllm_model.get_submodule(f'model.layers.{layer}.self_attn.k_proj')\n",
    "v2 = vllm_model.get_submodule(f'model.layers.{layer}.self_attn.v_proj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b211ba23-2ec5-4178-8ffc-02dd23848ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.equal(q.weight, q2.weight.reshape(-1,1))\n",
    "assert torch.equal(k.weight, k2.weight.reshape(-1,1))\n",
    "assert torch.equal(v.weight, v2.weight.reshape(-1,1))\n",
    "\n",
    "assert torch.equal(q.quant_state.absmax, q2.absmax.view(-1))\n",
    "assert torch.equal(k.quant_state.absmax, k2.absmax.view(-1))\n",
    "assert torch.equal(v.quant_state.absmax, v2.absmax.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba1a8dc3-8f40-418d-be5f-92980e0c1615",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# quant_state = QuantState(qkv.absmax.view(-1), dtype=torch.bfloat16)\n",
    "# quant_state.shape = torch.Size([qkv.weight.shape[0], qkv.weight.shape[1] * 2])\n",
    "# quant_state.blocksize = 64\n",
    "# quant_state.quant_type = \"nf4\"\n",
    "# quant_state.code = q.quant_state.code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2a3dfd8-d7e6-4a1a-95b8-061a01d009b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dq, dk, dv = dequantize_4bit(qkv.weight.view(-1,1), quant_state).split(4096,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a94fd8cb-06d5-4b2e-8aab-826029063161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert torch.equal(dq, dequantize_4bit(q.weight, q.quant_state))\n",
    "# assert torch.equal(dk, dequantize_4bit(k.weight, k.quant_state))\n",
    "# assert torch.equal(dv, dequantize_4bit(v.weight, v.quant_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0c3d0c9-2ce8-4260-ad84-e72f0438e18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2,4096).cuda().to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "51a0cfe7-842e-4e0b-8990-6a0a12e7b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(q(x),q2(x)[0])\n",
    "assert torch.allclose(k(x),k2(x)[0])\n",
    "assert torch.allclose(v(x),v2(x)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e576bf3f-db69-4827-9134-ee521a6a8f9d",
   "metadata": {},
   "source": [
    "#### Compare Attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b84b5bca-fdf7-4cd0-8048-b0cec850bb8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4096])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2cc351c-1b29-4fdd-b578-3dbd6141bc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = model.get_submodule(f'model.layers.{layer}.self_attn')\n",
    "attn2 = vllm_model.get_submodule(f'model.layers.{layer}.self_attn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "79637f4d-55a9-486b-b59a-448d0d0da1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_out1 = attn(x[None,...], position_ids=torch.tensor([[0,1]]).cuda(), attention_mask=torch.tensor([[[[1,0],[1,1]]]]).bool().cuda())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "68aea4d5-b4e1-4ce7-ba2d-504f21b0f3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [SequenceGroupMetadata(\"request_id\", True, {0:SequenceData([1,100])}, sampling_params=SamplingParams(temperature=0.0), block_tables=None)]\n",
    "attn_metadata = llm.llm_engine.model_executor.driver_worker.model_runner._prepare_prompt(s)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef967f62-2408-4408-8d4e-63ec7692c0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_out2 = attn2(torch.tensor([0,1]).cuda(), x, kv_cache=None, attn_metadata=attn_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2077a1a-f5d4-4ead-a168-74fb4e3c1c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(attn_out1, attn_out2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfba6f0e-593a-4495-a5d0-7d203042fa68",
   "metadata": {},
   "source": [
    "#### Compare O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d0af6dd4-099a-4979-96ec-93eca4405e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model.get_submodule(f'model.layers.{layer}.self_attn.o_proj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9dbb67a0-d4aa-4272-8bd6-03849d21544b",
   "metadata": {},
   "outputs": [],
   "source": [
    "o2 = vllm_model.get_submodule(f'model.layers.{layer}.self_attn.o_proj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bc3cb036-76f5-4667-811d-6f9b5eb66c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8388608, 1]), torch.Size([4096, 2048]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.weight.shape, o2.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a746c27a-6a96-49bf-8ae9-fc30c385df71",
   "metadata": {},
   "outputs": [],
   "source": [
    "o_out,_ = o2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3bba7a8b-35b9-43a3-a3ee-828ad230186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# o_out = o2.linear_method.apply_weights(o2.linear_weights, x, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6c8a3cf0-341a-4def-9a13-45434348cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(o_out,o(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37e0c02-29b6-4f38-afe4-25ced50687b0",
   "metadata": {},
   "source": [
    "#### Compare gate up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc7dcccf-7351-49c4-8ca6-2194297e60ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "gate = model.get_submodule(f'model.layers.{layer}.mlp.gate_proj')\n",
    "up   = model.get_submodule(f'model.layers.{layer}.mlp.up_proj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c6e743c5-2b88-460a-a544-b06dd35338f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gate_up = vllm_model.get_submodule(f'model.layers.{layer}.mlp.gate_up_proj')\n",
    "gate2 = vllm_model.get_submodule(f'model.layers.{layer}.mlp.gate_proj')\n",
    "up2 = vllm_model.get_submodule(f'model.layers.{layer}.mlp.up_proj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ce6baa0c-c155-4f9c-8581-bf2f9ea58d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gate_out = gate2.linear_method.apply_weights(gate2.linear_weights, x, None)\n",
    "gate_out,_ = gate2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7ae57042-a572-470f-80fe-c501b2923e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isclose(gate(x), gate_out).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e4dabe8d-e2bf-4b73-aca2-c9c2bc773761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# up_out = up2.linear_method.apply_weights(up2.linear_weights, x, None)\n",
    "up_out,_ = up2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6f1d0b9a-3ea1-43e1-9b1a-f75c55d7b223",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(up(x), up_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "efd9f350-b431-4ca9-9d71-51bc3cf9bd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert torch.equal(gate.weight, gate_up.weight.split(11008, dim=0)[0].reshape(-1,1))\n",
    "# assert torch.equal(up.weight, gate_up.weight.split(11008, dim=0)[1].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "be7eaccd-e212-4177-9e80-732736e7b6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert torch.equal(gate.quant_state.absmax, gate_up.absmax.view(-1).split(4096*11008//64)[0])\n",
    "# assert torch.equal(up.quant_state.absmax, gate_up.absmax.view(-1).split(4096*11008//64)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "25d12aee-255e-4254-b869-7e7cd22e379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gate_up.weight.shape, gate_up.gather_output, gate_up.bias, gate_up.linear_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "94bf2a25-8703-4905-9887-ad8f06d93c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gate, up, gate_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c507857b-8702-4545-8afe-082326415fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gate_up_out = gate_up.linear_method.apply_weights(gate_up.linear_weights, x, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bb6c3f07-ed0c-48a7-988f-5e3c23ca942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gate_up_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "026f67c7-84b9-498a-9f02-583713e901fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fgate, fup = gate_up_out.split(11008,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7ca564a0-ed74-449d-bbd7-aa66011644c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fgate.shape, fup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7a5167b0-1250-4708-ade8-fc5d33fa2357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.isclose(fgate, gate(x)).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aac5f577-1cfe-4738-84d8-0dc5c091e5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.isclose(fup, up(x)).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "65e4136f-8693-436f-9d39-0f3afbd7b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (fgate - gate(x)).abs().max(), (fup - up(x)).abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "700825c5-a37a-4676-93f1-a1bff4417b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fgate - gate(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f46a385c-edc3-47ff-847f-58f29d68ee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gate, up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f8232bf3-0688-4741-a3b2-26886452e09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gate(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "70cc12c1-7345-4c82-9f43-7a57f84b9c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quant_state.absmax = gate_up.absmax.view(-1).split(4096*11008//64)[0]\n",
    "# quant_state.shape = torch.Size([11008, 4096])\n",
    "# bnb.matmul_4bit(x, gate_up.weight.split(11008, dim=0)[0].reshape(-1,1).t(), quant_state=quant_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "645d0635-963b-4891-ab28-53cc0b2d02d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.isclose(gate(x), bnb.matmul_4bit(x, gate_up.weight.split(11008, dim=0)[0].reshape(-1,1).t(), quant_state=quant_state)).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75fac54-b9b3-4021-8902-39dcb82e10bc",
   "metadata": {},
   "source": [
    "#### Compare down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5677cacd-d5b6-4b1c-8e44-9faeb1b7ce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "down = model.get_submodule(f'model.layers.{layer}.mlp.down_proj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ab56684f-0eda-478d-8b84-45181f96e118",
   "metadata": {},
   "outputs": [],
   "source": [
    "down2 = vllm_model.get_submodule(f'model.layers.{layer}.mlp.down_proj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1d0a262b-62b0-44f9-b141-5525f4dea87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.equal(down.weight, down2.weight.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e3157d4d-0bcd-4321-8a9a-31b29834008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.equal(down.quant_state.absmax, down2.absmax.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e47501a0-4577-4099-a00f-6a9e18ad6b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = torch.randn(2,11008).cuda().to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2ea8b141-9b7d-4c9f-9fe4-ee6f2c5915c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# down_out = down2.linear_method.apply_weights(down2.linear_weights, x2, None)\n",
    "down_out,_ = down2(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1408068e-90ed-40cc-9559-9a0569ebfa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(down_out,down(x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db40cb18-6317-4cc0-b314-7eeffbb325ba",
   "metadata": {},
   "source": [
    "#### Compare MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "67779aaa-f7c9-41ef-935f-dfa7ccec77af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4096])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1067f030-2ae7-4d56-b20d-f149b69c0e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = model.get_submodule(f'model.layers.{layer}.mlp')\n",
    "mlp2 = vllm_model.get_submodule(f'model.layers.{layer}.mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "471a7388-4001-4790-bd40-9dacc5ea8ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_out1 = mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c452a5f6-204a-4096-b220-3101bc3b5040",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_out2 = mlp2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4639bf43-9665-4172-baee-6dca155925a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(mlp_out1, mlp_out2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2506dfcf-7803-4109-829e-ca0e6e97c8fd",
   "metadata": {},
   "source": [
    "#### Compare decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1fb177ee-00ab-40d5-b085-5225c3dcdd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in range(model.config.num_hidden_layers):\n",
    "    dec = model.model.layers[layer]\n",
    "    dec2 = vllm_model.model.layers[layer]\n",
    "    \n",
    "    x, x.shape\n",
    "    \n",
    "    out1 = dec(x[None,...], \n",
    "                 position_ids=torch.tensor([[0,1]]).cuda(), \n",
    "                 attention_mask=torch.tensor([[[[1,0],[1,1]]]]).bool().cuda())\n",
    "    \n",
    "    out1[0]\n",
    "    \n",
    "    s = [SequenceGroupMetadata(\"request_id\", True, {0:SequenceData([7,42])}, sampling_params=SamplingParams(temperature=0.0), block_tables=None)]\n",
    "    attn_metadata = llm.llm_engine.model_executor.driver_worker.model_runner._prepare_prompt(s)[2]\n",
    "    \n",
    "    out2 = dec2(hidden_states=x, \n",
    "                      positions=torch.tensor([0,1]).cuda(), \n",
    "                      kv_cache=None, \n",
    "                      attn_metadata=attn_metadata, \n",
    "                      residual=x)\n",
    "    \n",
    "    assert torch.allclose(out1[0], out2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bf971e9e-fce6-4a27-8775-7261086abcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import collections\n",
    "from typing import DefaultDict, Tuple, List, Dict\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "\n",
    "def save_activations(\n",
    "        activations: DefaultDict,\n",
    "        name: str,\n",
    "        module: nn.Module,\n",
    "        inp: Tuple,\n",
    "        out: torch.Tensor\n",
    ") -> None:\n",
    "    \"\"\"PyTorch Forward hook to save outputs at each forward\n",
    "    pass. Mutates specified dict objects with each fwd pass.\n",
    "    \"\"\"\n",
    "    if \"layer\" in name:\n",
    "        activations[name].append(out[0].detach().cpu())\n",
    "    else:\n",
    "        activations[name].append(out.detach().cpu())\n",
    "def register_activation_hooks(\n",
    "        model: nn.Module,\n",
    "        layers_to_save: List[str]\n",
    ") -> DefaultDict[List, torch.Tensor]:\n",
    "    \"\"\"Registers forward hooks in specified layers.\n",
    "    Parameters\n",
    "    ----------\n",
    "    model:\n",
    "        PyTorch model\n",
    "    layers_to_save:\n",
    "        Module names within ``model`` whose activations we want to save.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    activations_dict:\n",
    "        dict of lists containing activations of specified layers in\n",
    "        ``layers_to_save``.\n",
    "    \"\"\"\n",
    "    activations_dict = collections.defaultdict(list)\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        if any(name.endswith(l) for l in layers_to_save):\n",
    "            module.register_forward_hook(\n",
    "                partial(save_activations, activations_dict, name)\n",
    "            )\n",
    "    return activations_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "767be7c3-3e7d-414b-8ab7-2537aad82fda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, module in model.named_modules(): \n",
    "    module._forward_hooks = OrderedDict()\n",
    "    # print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9f56796b-d63a-4684-84d0-8f6717617ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in vllm_model.named_modules(): \n",
    "    module._forward_hooks = OrderedDict()\n",
    "    # print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "093842a8-2a27-4c22-a6d3-d0b4a0e6d381",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_to_save = [f\"layers.{i}\" for i in range(model.config.num_hidden_layers)] + [\".norm\", \"lm_head\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a3fcf6db-d53e-4d37-ad03-9b3675bd5272",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_saved_activations = register_activation_hooks(model, layers_to_save=layers_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2f2007f1-7a09-4bfc-bc19-a486e3a63f86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    _ = model(input_ids, \n",
    "              position_ids=torch.tensor([[0,1]]).cuda(), \n",
    "              attention_mask=torch.tensor([[[[1,0],\n",
    "                                             [1,1]]]]).bool().cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0b891d82-2813-4194-992f-a67fe1101ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vllm_saved_activations = register_activation_hooks(vllm_model, layers_to_save=layers_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4afeb43a-c192-4ce2-a33f-630ca0c59d48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    _ = vllm_model(input_ids=input_ids.flatten(), \n",
    "                  positions=torch.tensor([0,1]).cuda(), \n",
    "                  kv_caches=[None]*model.config.num_hidden_layers, \n",
    "                  attn_metadata=attn_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e8c371be-e8db-4e5e-beb9-3c3de78ab107",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.0 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.1 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.2 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.3 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.4 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.5 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.6 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.7 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.8 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.9 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.10 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.11 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.12 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.13 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.14 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.15 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.16 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.17 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.18 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.19 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.20 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.21 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.22 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.23 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.24 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.25 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.26 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.27 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.28 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.29 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.30 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.layers.31 torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n",
      "model.norm torch.Size([1, 2, 4096]) torch.Size([2, 4096]) True\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[153], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m hf_saved_activations\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(k, v[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, \u001b[43mvllm_saved_activations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape,\n\u001b[1;32m      3\u001b[0m           torch\u001b[38;5;241m.\u001b[39mallclose(v[\u001b[38;5;241m0\u001b[39m], vllm_saved_activations[k][\u001b[38;5;241m0\u001b[39m]))\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for k,v in hf_saved_activations.items():\n",
    "    print(k, v[0].shape, vllm_saved_activations[k][0].shape,\n",
    "          torch.allclose(v[0], vllm_saved_activations[k][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "43c886b2-7286-4e1c-99e4-785df81060da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[-5.8438, -0.5234,  4.2500,  ..., -3.7656, -5.1250, -2.0312],\n",
       "          [ 1.7031,  0.5000, -0.0359,  ...,  2.2656,  2.9688,  1.8672]]],\n",
       "        dtype=torch.bfloat16)]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_saved_activations['lm_head']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "158e1af5-155f-43c0-9489-7e7dd7105956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vllm_saved_activations['lm_head']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "17a5da10-71ab-47f1-b843-671e2b13032e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5273, -0.7305, -1.4844,  ..., -0.4082, -0.2871,  3.0781],\n",
       "         [ 0.0854, -0.0349, -0.0530,  ...,  0.0356, -0.0376,  0.1953]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.norm(hf_saved_activations['model.layers.31'][0].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fb5ef8af-58de-482e-b3d8-c78371d44ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5273, -0.7305, -1.4844,  ..., -0.4082, -0.2871,  3.0781],\n",
       "        [ 0.0854, -0.0349, -0.0530,  ...,  0.0356, -0.0376,  0.1953]],\n",
       "       device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vllm_model.model.norm(vllm_saved_activations['model.layers.31'][0].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "662d5621-0798-427a-8f1a-e097a53e3b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1.8672, 1.8672, 1.8047,  ..., 1.7188, 1.8281, 1.6016], device='cuda:0',\n",
       "       dtype=torch.bfloat16, requires_grad=True)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.norm.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "90b74076-05b8-4ca5-965f-d7c92ed10d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1.8672, 1.8672, 1.8047,  ..., 1.7188, 1.8281, 1.6016], device='cuda:0',\n",
       "       dtype=torch.bfloat16, requires_grad=True)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vllm_model.model.norm.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "44d255fd-eff8-4752-8383-f52c48f1ccbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m      \u001b[0mvllm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mType:\u001b[0m           ParallelLMHead\n",
       "\u001b[0;31mString form:\u001b[0m    ParallelLMHead()\n",
       "\u001b[0;31mFile:\u001b[0m           ~/git/vllm-fork/vllm/model_executor/layers/vocab_parallel_embedding.py\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mParallelLMHead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVocabParallelEmbedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Parallelized LM head.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Output logits weight matrices used in the Sampler. The weight and bias\u001b[0m\n",
       "\u001b[0;34m    tensors are padded to make sure they are divisible by the number of\u001b[0m\n",
       "\u001b[0;34m    model parallel GPUs.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Args:\u001b[0m\n",
       "\u001b[0;34m        num_embeddings: vocabulary size.\u001b[0m\n",
       "\u001b[0;34m        embedding_dim: size of hidden state.\u001b[0m\n",
       "\u001b[0;34m        bias: whether to use bias.\u001b[0m\n",
       "\u001b[0;34m        params_dtype: type of the parameters.\u001b[0m\n",
       "\u001b[0;34m        org_num_embeddings: original vocabulary size (without LoRA).\u001b[0m\n",
       "\u001b[0;34m        padding_size: padding size for the vocabulary.\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0mnum_embeddings\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0membedding_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0mparams_dtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0morg_num_embeddings\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0mpadding_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDEFAULT_VOCAB_PADDING_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                         \u001b[0morg_num_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_embeddings_per_partition\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                            \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mset_weight_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"parallel_dim\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"weight_loader\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_loader\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bias\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mdel\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LMHead's weights should be used in the sampler.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mInit docstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vllm_model.lm_head??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91d586a-d257-4e22-877c-1a56b18cf8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eda9ca-3b6e-423b-a6c1-dcc650aafc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9187ed5-5e80-4724-b578-b8c1423b0df8",
   "metadata": {},
   "source": [
    "#### Compare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "161d0cef-3c9a-402f-a8e2-7375b93e83b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out1 = model(input_ids, \n",
    "             position_ids=torch.tensor([[0,1]]).cuda(), \n",
    "             attention_mask=torch.tensor([[[[1,0],[1,1]]]]).bool().cuda()).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "86281556-da6d-49ce-9328-49165adc6d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [SequenceGroupMetadata(\"request_id\", True, {0:SequenceData([7,42])}, sampling_params=SamplingParams(temperature=0.0), block_tables=None)]\n",
    "attn_metadata = llm.llm_engine.model_executor.driver_worker.model_runner._prepare_prompt(s)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1a1d441a-af87-4991-99fb-84dd1b806326",
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = vllm_model(input_ids=input_ids.flatten(), \n",
    "                  positions=torch.tensor([0,1]).cuda(), \n",
    "                  kv_caches=[None]*model.config.num_hidden_layers, \n",
    "                  attn_metadata=attn_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3da33ebd-0ba6-4e2e-a806-0ad9926f5e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-5.8438, -0.5234,  4.2500,  ..., -3.7656, -5.1250, -2.0312],\n",
       "         [ 1.7031,  0.5000, -0.0359,  ...,  2.2656,  2.9688,  1.8672]]],\n",
       "       device='cuda:0', grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7a64f322-b7a9-433f-8e0e-4e116c96e518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5273, -0.7305, -1.4844,  ..., -0.4082, -0.2871,  3.0781],\n",
       "        [ 0.0854, -0.0349, -0.0530,  ...,  0.0356, -0.0376,  0.1953]],\n",
       "       device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "44e5541c-3904-40a7-a8f4-ca9375d3a056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0039,  0.0032, -0.0071,  ...,  0.0053, -0.0082,  0.0070],\n",
       "        [-0.0315,  0.0466, -0.0023,  ..., -0.0211,  0.0173,  0.0334],\n",
       "        [-0.0125,  0.0037,  0.0195,  ..., -0.0271,  0.0143, -0.0082],\n",
       "        ...,\n",
       "        [-0.0281, -0.0195, -0.0024,  ...,  0.0123, -0.0117, -0.0237],\n",
       "        [ 0.0229,  0.0255,  0.0315,  ...,  0.0067, -0.0092, -0.0058],\n",
       "        [ 0.0080, -0.0088,  0.0063,  ..., -0.0293, -0.0200,  0.0337]],\n",
       "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lm_head.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e9b2b6e1-fda3-4260-9f31-687669d03c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0039,  0.0032, -0.0071,  ...,  0.0053, -0.0082,  0.0070],\n",
       "        [-0.0315,  0.0466, -0.0023,  ..., -0.0211,  0.0173,  0.0334],\n",
       "        [-0.0125,  0.0037,  0.0195,  ..., -0.0271,  0.0143, -0.0082],\n",
       "        ...,\n",
       "        [-0.0281, -0.0195, -0.0024,  ...,  0.0123, -0.0117, -0.0237],\n",
       "        [ 0.0229,  0.0255,  0.0315,  ...,  0.0067, -0.0092, -0.0058],\n",
       "        [ 0.0080, -0.0088,  0.0063,  ..., -0.0293, -0.0200,  0.0337]],\n",
       "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vllm_model.lm_head.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d1e850-ad5b-4a31-97ec-793edba52e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef79c5b7-5a79-4498-8b28-df8f32802cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3ceca3c-ee2d-49c5-b54f-478b60945cff",
   "metadata": {},
   "source": [
    "### Compare Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3e7ca28d-df4e-4c9e-8d68-244dc4d98eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b9546560-2af1-4c77-986f-0a60c57d7505",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm.sequence import SequenceGroupMetadata, SequenceData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b450e2d2-418c-432c-a0cd-502bbfad2e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import collections\n",
    "from typing import DefaultDict, Tuple, List, Dict\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "def save_activations(\n",
    "        activations: DefaultDict,\n",
    "        name: str,\n",
    "        module: nn.Module,\n",
    "        inp: Tuple,\n",
    "        out: torch.Tensor\n",
    ") -> None:\n",
    "    \"\"\"PyTorch Forward hook to save outputs at each forward\n",
    "    pass. Mutates specified dict objects with each fwd pass.\n",
    "    \"\"\"\n",
    "    if any(l in name for l in [\"qkv\", \"q_proj\",\"k_proj\",\"v_proj\", \"o_proj\", \"gate_up_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]):\n",
    "        if len(out) > 1:\n",
    "            out = out[0]\n",
    "    activations[name].append(out.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "85dfb724-1c57-47c4-8c4a-27feafa568e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_activation_hooks(\n",
    "        model: nn.Module,\n",
    "        layers_to_save: List[str]\n",
    ") -> DefaultDict[List, torch.Tensor]:\n",
    "    \"\"\"Registers forward hooks in specified layers.\n",
    "    Parameters\n",
    "    ----------\n",
    "    model:\n",
    "        PyTorch model\n",
    "    layers_to_save:\n",
    "        Module names within ``model`` whose activations we want to save.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    activations_dict:\n",
    "        dict of lists containing activations of specified layers in\n",
    "        ``layers_to_save``.\n",
    "    \"\"\"\n",
    "    activations_dict = collections.defaultdict(list)\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        if any(l in name for l in layers_to_save):\n",
    "            module.register_forward_hook(\n",
    "                partial(save_activations, activations_dict, name)\n",
    "            )\n",
    "    return activations_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03cf752-84c9-43af-9d0d-523dffb3388a",
   "metadata": {},
   "source": [
    "### Regular Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5497346-31de-4afb-8426-d23d1710870a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f81a0a1855754aabba7f6c0e334712f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-hf\", torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13b67693-aa60-4e15-9869-f31460cdf642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 04-03 14:32:47 config.py:744] Casting torch.float16 to torch.bfloat16.\n",
      "INFO 04-03 14:32:47 llm_engine.py:70] Initializing an LLM engine (v0.3.3) with config: model='meta-llama/Llama-2-7b-hf', tokenizer='meta-llama/Llama-2-7b-hf', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=0)\n",
      "INFO 04-03 14:32:47 pynccl_utils.py:13] vLLM is using nccl==2.18.1\n",
      "INFO 04-03 14:32:47 selector.py:44] flash_attn is not found.\n",
      "INFO 04-03 14:32:47 selector.py:20] Using XFormers backend.\n",
      "INFO 04-03 14:32:50 weight_utils.py:177] Using model weights format ['*.safetensors']\n",
      "INFO 04-03 14:32:58 model_runner.py:104] Loading model weights took 12.5523 GB\n",
      "INFO 04-03 14:33:00 gpu_executor.py:94] # GPU blocks: 437, # CPU blocks: 512\n",
      "INFO 04-03 14:33:02 model_runner.py:770] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 04-03 14:33:02 model_runner.py:774] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 04-03 14:33:09 model_runner.py:846] Graph capturing finished in 8 secs.\n",
      "INFO 04-03 14:33:09 block_manager_v1.py:239] disable automatic prefix caching\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(model=\"meta-llama/Llama-2-7b-hf\", tokenizer=\"meta-llama/Llama-2-7b-hf\", dtype=\"bfloat16\", gpu_memory_utilization=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ab9240b-71b2-4240-adb3-701519684cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vllm_model = llm.llm_engine.model_executor.driver_worker.model_runner.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16b05929-810a-44d8-b248-6f840012c40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in hf_model.named_modules(): \n",
    "    module._forward_hooks = OrderedDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e0c861d-35f1-4363-87de-8da91719e03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_saved_activations = register_activation_hooks(hf_model, \n",
    "                                              layers_to_save=[\"embed\", \"q_proj\", \"k_proj\", \"v_proj\", \n",
    "                                                              \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\", \"lm_head\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a34afa2-817e-4501-9e21-46c87c122cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.tensor([[7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8426d20-f88f-415d-9960-580261293f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    _ = hf_model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7211678-23ef-401f-8be8-bd4df96a8f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "vllm_saved_activations = register_activation_hooks(vllm_model, \n",
    "                                              layers_to_save=[\"embed\", \"qkv_proj\", \"o_proj\", \"gate_up_proj\", \"down_proj\", \"lm_head\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfd28a6a-50b3-49d6-84e8-ac25da0eec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.tensor([7]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9abf4e90-116c-4323-adeb-42da5a4f8269",
   "metadata": {},
   "outputs": [],
   "source": [
    "kv_caches = [None] * len(vllm_model.model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be47df25-1121-444e-8d01-e66630189407",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = torch.tensor([0]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "127619bd-045e-48ea-bdbe-b657cacb8fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [SequenceGroupMetadata(\"1\", True, {0:SequenceData([7,42,1003])}, sampling_params=SamplingParams(temperature=0.0), block_tables=None)]\n",
    "attn_metadata = llm.llm_engine.model_executor.driver_worker.model_runner._prepare_prompt(s)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3359649-a4b2-45a8-8974-1792eff1a60c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    _ = vllm_model(inp, positions, kv_caches, attn_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2290b72-5979-4f4e-a74a-57b9dd89469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_embed_output = hf_saved_activations['model.embed_tokens'][0]\n",
    "vllm_embed_output = vllm_saved_activations['model.embed_tokens'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8b064f1-1c3d-4f18-b6b8-da1271878434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(hf_embed_output - vllm_embed_output).norm() / hf_embed_output.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19678f1b-daef-42f7-ade7-579648cc7895",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas = {k:[] for k in [\"q\",\"k\",\"v\",\"o\",\"gate\",\"up\",\"down\"]}\n",
    "\n",
    "for layer in range(len(vllm_model.model.layers)):\n",
    "    hf_q_output = hf_saved_activations[f'model.layers.{layer}.self_attn.q_proj'][0]\n",
    "    vllm_q_output = vllm_saved_activations[f'model.layers.{layer}.self_attn.qkv_proj'][0][:,:4096]\n",
    "    deltas[\"q\"].append((hf_q_output - vllm_q_output).norm(p=2))\n",
    "    \n",
    "    hf_k_output = hf_saved_activations[f'model.layers.{layer}.self_attn.k_proj'][0]\n",
    "    vllm_k_output = vllm_saved_activations[f'model.layers.{layer}.self_attn.qkv_proj'][0][:,4096:4096*2]\n",
    "    deltas[\"k\"].append((hf_k_output - vllm_k_output).norm(p=2))\n",
    "    \n",
    "    hf_v_output = hf_saved_activations[f'model.layers.{layer}.self_attn.v_proj'][0]\n",
    "    vllm_v_output = vllm_saved_activations[f'model.layers.{layer}.self_attn.qkv_proj'][0][:,4096*2:]\n",
    "    deltas[\"v\"].append((hf_v_output - vllm_v_output).norm(p=2))\n",
    "    \n",
    "    hf_o_output = hf_saved_activations[f'model.layers.{layer}.self_attn.o_proj'][0]\n",
    "    vllm_o_output = vllm_saved_activations[f'model.layers.{layer}.self_attn.o_proj'][0]\n",
    "    deltas[\"o\"].append((hf_o_output - vllm_o_output).norm(p=2))\n",
    "    \n",
    "    hf_gate_output = hf_saved_activations[f'model.layers.{layer}.mlp.gate_proj'][0]\n",
    "    vllm_gate_output = vllm_saved_activations[f'model.layers.{layer}.mlp.gate_up_proj'][0][:,:11008]\n",
    "    deltas[\"gate\"].append((hf_gate_output - vllm_gate_output).norm(p=2))\n",
    "    \n",
    "    hf_up_output = hf_saved_activations[f'model.layers.{layer}.mlp.up_proj'][0]\n",
    "    vllm_up_output = vllm_saved_activations[f'model.layers.{layer}.mlp.gate_up_proj'][0][:,11008:]\n",
    "    deltas[\"up\"].append((hf_up_output - vllm_up_output).norm(p=2))\n",
    "    \n",
    "    hf_down_output = hf_saved_activations[f'model.layers.{layer}.mlp.down_proj'][0]\n",
    "    vllm_down_output = vllm_saved_activations[f'model.layers.{layer}.mlp.down_proj'][0]\n",
    "    deltas[\"down\"].append((hf_down_output - vllm_down_output).norm(p=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c23a286-44b4-450a-81bd-fe82352e5691",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas = {k:torch.stack(v).float().numpy() for k,v in deltas.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ecb6b53-6514-437b-a692-7060a1073e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "\n",
    "# Loop through the dictionary and plot each line with a label\n",
    "for key, values in deltas.items():\n",
    "    ax.plot(values, label=key)\n",
    "    ax.set_xticks(range(len(values)))\n",
    "\n",
    "# Adding a legend to distinguish the lines\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "75bbd723-ba8e-429f-aa16-0a777604414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(hf_saved_activations, \"/home/ubuntu/models/debug/hf_saved_activations\")\n",
    "torch.save(vllm_saved_activations, \"/home/ubuntu/models/debug/vllm_saved_activations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dd3e3f-9fcf-4854-8f06-cfc6488fb815",
   "metadata": {},
   "source": [
    "### Quantized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "09740976-a219-4148-af45-9cbcbd9b0b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in model.named_modules(): \n",
    "    module._forward_hooks = OrderedDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "302e1a59-0b32-49be-8249-554ef4704717",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_saved_activations = register_activation_hooks(model, \n",
    "                                              layers_to_save=[\"embed\", \"q_proj\", \"k_proj\", \"v_proj\", \n",
    "                                                              \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\", \"lm_head\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ac4cbb47-941a-48ef-b497-227e9c25ccce",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.tensor([[7,42]]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "890a098d-2da9-4fe8-8f08-48ea9c75e30d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    _ = model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "500b4a00-1155-453d-ad3f-13924f57da05",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in vllm_model.named_modules(): \n",
    "    module._forward_hooks = OrderedDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b48d0307-7160-4146-a0b6-281e9775bd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "vllm_saved_activations = register_activation_hooks(vllm_model, \n",
    "                                              layers_to_save=[\"embed\", \"qkv_proj\",\"q_proj\", \"k_proj\", \"v_proj\", \n",
    "                                                              \"o_proj\", \"gate_proj\", \"up_proj\",\n",
    "                                                              \"gate_up_proj\", \"down_proj\", \"lm_head\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1dd40d7b-54b9-448e-80e4-d5ce2566b8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.tensor([7,42]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a29434c5-d674-4072-ba53-83a6c64eeab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kv_caches = [None] * len(vllm_model.model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "044d13c0-0feb-405a-8f46-df022d780fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = torch.tensor([0,1]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "fd142820-099c-44ca-81be-4a426eaa80b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = [SequenceGroupMetadata(\"request_id\", True, {0:SequenceData([7,42])}, sampling_params=SamplingParams(temperature=0.0), block_tables=None)]\n",
    "attn_metadata = llm.llm_engine.model_executor.driver_worker.model_runner._prepare_prompt(s)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "180e049a-e8d9-45de-836d-f42577953b61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    _ = vllm_model(inp, positions, kv_caches, attn_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "4b340558-3242-46f4-887d-d57a3969dac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf_saved_activations['model.layers.0.self_attn.q_proj'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8783794c-ec6b-47c3-9b31-d8c00037da1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vllm_saved_activations['model.layers.0.self_attn.qkv_proj'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "712ada76-5a1e-4592-b356-94f3a9f19464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf_embed_output = hf_saved_activations['model.embed_tokens'][0]\n",
    "# vllm_embed_output = vllm_saved_activations['model.embed_tokens'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "eddd20ff-dfd1-4cf1-80f4-be3fed05bc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (hf_embed_output - vllm_embed_output).norm() / hf_embed_output.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8736f8d8-10b6-471b-a4a4-1ccb340ad2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas = {k:[] for k in [\"q\",\"k\",\"v\",\"o\",\"gate\",\"up\",\"down\"]}\n",
    "\n",
    "for layer in range(len(vllm_model.model.layers)):\n",
    "    hf_q_output = hf_saved_activations[f'model.layers.{layer}.self_attn.q_proj'][0]\n",
    "    # vllm_q_output = vllm_saved_activations[f'model.layers.{layer}.self_attn.qkv_proj'][0][:,:4096]\n",
    "    vllm_q_output = vllm_saved_activations[f'model.layers.{layer}.self_attn.q_proj'][0]\n",
    "    deltas[\"q\"].append((hf_q_output - vllm_q_output).norm(p=2))\n",
    "    \n",
    "    hf_k_output = hf_saved_activations[f'model.layers.{layer}.self_attn.k_proj'][0]\n",
    "    # vllm_k_output = vllm_saved_activations[f'model.layers.{layer}.self_attn.qkv_proj'][0][:,4096:4096*2]\n",
    "    vllm_k_output = vllm_saved_activations[f'model.layers.{layer}.self_attn.k_proj'][0]\n",
    "    deltas[\"k\"].append((hf_k_output - vllm_k_output).norm(p=2))\n",
    "    \n",
    "    hf_v_output = hf_saved_activations[f'model.layers.{layer}.self_attn.v_proj'][0]\n",
    "    # vllm_v_output = vllm_saved_activations[f'model.layers.{layer}.self_attn.qkv_proj'][0][:,4096*2:]\n",
    "    vllm_v_output = vllm_saved_activations[f'model.layers.{layer}.self_attn.v_proj'][0]\n",
    "    deltas[\"v\"].append((hf_v_output - vllm_v_output).norm(p=2))\n",
    "    \n",
    "    hf_o_output = hf_saved_activations[f'model.layers.{layer}.self_attn.o_proj'][0]\n",
    "    vllm_o_output = vllm_saved_activations[f'model.layers.{layer}.self_attn.o_proj'][0]\n",
    "    deltas[\"o\"].append((hf_o_output - vllm_o_output).norm(p=2))\n",
    "    \n",
    "    hf_gate_output = hf_saved_activations[f'model.layers.{layer}.mlp.gate_proj'][0]\n",
    "    # vllm_gate_output = vllm_saved_activations[f'model.layers.{layer}.mlp.gate_up_proj'][0][:,:11008]\n",
    "    vllm_gate_output = vllm_saved_activations[f'model.layers.{layer}.mlp.gate_proj'][0]\n",
    "    deltas[\"gate\"].append((hf_gate_output - vllm_gate_output).norm(p=2))\n",
    "    \n",
    "    hf_up_output = hf_saved_activations[f'model.layers.{layer}.mlp.up_proj'][0]\n",
    "    # vllm_up_output = vllm_saved_activations[f'model.layers.{layer}.mlp.gate_up_proj'][0][:,11008:]\n",
    "    vllm_up_output = vllm_saved_activations[f'model.layers.{layer}.mlp.up_proj'][0]\n",
    "    deltas[\"up\"].append((hf_up_output - vllm_up_output).norm(p=2))\n",
    "    \n",
    "    hf_down_output = hf_saved_activations[f'model.layers.{layer}.mlp.down_proj'][0]\n",
    "    vllm_down_output = vllm_saved_activations[f'model.layers.{layer}.mlp.down_proj'][0]\n",
    "    deltas[\"down\"].append((hf_down_output - vllm_down_output).norm(p=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "033f6a59-08d2-48c0-9c76-510bfc344d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas = {k:torch.stack(v).float().numpy() for k,v in deltas.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "98ebb0db-c3bc-49e8-93ac-342849991919",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q': array([0.        , 0.22167969, 0.25390625, 0.33984375, 0.3125    ,\n",
       "        0.328125  , 0.31640625, 0.30078125, 0.27539062, 0.26367188,\n",
       "        0.26171875, 0.29101562, 0.29296875, 0.3359375 , 0.34960938,\n",
       "        0.36328125, 0.37890625, 0.34765625, 0.35742188, 0.39257812,\n",
       "        0.59375   , 0.58203125, 0.58203125, 0.55859375, 0.609375  ,\n",
       "        0.58984375, 0.65234375, 0.65234375, 0.734375  , 0.6484375 ,\n",
       "        0.8203125 , 1.734375  ], dtype=float32),\n",
       " 'k': array([0.        , 0.23242188, 0.31054688, 0.40429688, 0.36914062,\n",
       "        0.36328125, 0.31445312, 0.28125   , 0.296875  , 0.26953125,\n",
       "        0.26953125, 0.265625  , 0.28320312, 0.31054688, 0.328125  ,\n",
       "        0.34375   , 0.359375  , 0.44726562, 0.42578125, 0.453125  ,\n",
       "        0.80859375, 0.79296875, 0.7578125 , 0.6875    , 0.828125  ,\n",
       "        0.73828125, 0.7734375 , 0.609375  , 0.6875    , 0.765625  ,\n",
       "        0.80859375, 1.6953125 ], dtype=float32),\n",
       " 'v': array([0.        , 0.02539062, 0.02770996, 0.04077148, 0.04125977,\n",
       "        0.0625    , 0.08203125, 0.07861328, 0.08544922, 0.09033203,\n",
       "        0.09472656, 0.10009766, 0.09960938, 0.10644531, 0.11132812,\n",
       "        0.12011719, 0.12792969, 0.12792969, 0.14648438, 0.15625   ,\n",
       "        0.15820312, 0.19335938, 0.18847656, 0.19238281, 0.19140625,\n",
       "        0.20800781, 0.23339844, 0.23144531, 0.26171875, 0.28710938,\n",
       "        0.42773438, 1.265625  ], dtype=float32),\n",
       " 'o': array([4.84466553e-04, 1.94531250e+00, 1.34887695e-02, 1.74560547e-02,\n",
       "        1.92871094e-02, 2.92968750e-02, 3.19824219e-02, 3.32031250e-02,\n",
       "        3.75976562e-02, 3.80859375e-02, 3.73535156e-02, 6.07910156e-02,\n",
       "        4.44335938e-02, 5.81054688e-02, 4.95605469e-02, 5.41992188e-02,\n",
       "        6.54296875e-02, 7.37304688e-02, 8.34960938e-02, 8.39843750e-02,\n",
       "        1.00097656e-01, 1.03027344e-01, 2.14843750e-01, 1.47460938e-01,\n",
       "        1.22070312e-01, 1.31835938e-01, 1.63085938e-01, 1.68945312e-01,\n",
       "        1.67968750e-01, 2.27539062e-01, 5.93750000e-01, 2.43750000e+00],\n",
       "       dtype=float32),\n",
       " 'gate': array([ 0.03051758, 11.375     ,  0.0546875 ,  0.09033203,  0.09960938,\n",
       "         0.11376953,  0.12207031,  0.13671875,  0.17773438,  0.18652344,\n",
       "         0.17089844,  0.23730469,  0.23828125,  0.28125   ,  0.29296875,\n",
       "         0.28710938,  0.34960938,  0.296875  ,  0.31445312,  0.39453125,\n",
       "         0.33203125,  0.36914062,  0.40234375,  0.41796875,  0.44335938,\n",
       "         0.45898438,  0.51171875,  0.5703125 ,  0.609375  ,  0.8515625 ,\n",
       "         1.0234375 ,  5.25      ], dtype=float32),\n",
       " 'up': array([0.02526855, 6.625     , 0.04370117, 0.07861328, 0.08984375,\n",
       "        0.09130859, 0.09619141, 0.10644531, 0.13964844, 0.13574219,\n",
       "        0.13671875, 0.15917969, 0.16992188, 0.19140625, 0.20703125,\n",
       "        0.22460938, 0.25976562, 0.24902344, 0.28320312, 0.3046875 ,\n",
       "        0.30664062, 0.33007812, 0.35351562, 0.3671875 , 0.3828125 ,\n",
       "        0.4140625 , 0.43554688, 0.48632812, 0.55078125, 1.0234375 ,\n",
       "        1.0390625 , 4.5625    ], dtype=float32),\n",
       " 'down': array([7.9345703e-03, 6.6400000e+02, 1.0009766e-02, 9.4604492e-03,\n",
       "        2.1191406e-01, 1.0803223e-02, 1.1413574e-02, 1.4404297e-02,\n",
       "        2.0141602e-02, 1.7944336e-02, 1.8676758e-02, 2.0996094e-02,\n",
       "        1.9897461e-02, 2.2949219e-02, 2.5024414e-02, 3.3935547e-02,\n",
       "        4.3701172e-02, 2.8808594e-02, 3.5400391e-02, 1.9824219e-01,\n",
       "        3.6621094e-02, 3.8330078e-02, 4.1015625e-02, 5.5175781e-02,\n",
       "        4.4921875e-02, 6.1767578e-02, 7.4218750e-02, 9.8144531e-02,\n",
       "        3.5937500e-01, 1.0437500e+01, 5.1250000e+01, 2.1875000e+00],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3ca8f38a-abff-4ca2-90a6-8b969768d4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "\n",
    "# Loop through the dictionary and plot each line with a label\n",
    "for key, values in deltas.items():\n",
    "    ax.plot(values, label=key)\n",
    "    ax.set_xticks(range(len(values)))\n",
    "    \n",
    "# Adding a legend to distinguish the lines\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fb39a463-0340-410f-acd5-fbcd8f0c214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(hf_saved_activations, \"/home/ubuntu/models/debug/quant_hf_saved_activations\")\n",
    "torch.save(vllm_saved_activations, \"/home/ubuntu/models/debug/quant_vllm_saved_activations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792c63e3-5af5-4550-92b6-13d737d60816",
   "metadata": {},
   "source": [
    "### Loaded vs Saved Weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cbda28c-cab0-476e-924b-6a6cced74626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_quant_state(absmax, shape):\n",
    "    quant_state = QuantState(absmax, dtype=torch.bfloat16)\n",
    "    quant_state.shape = torch.Size(shape)\n",
    "    quant_state.blocksize = 64\n",
    "    quant_state.quant_type = \"nf4\"\n",
    "    quant_state.code = quant_map\n",
    "    return quant_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c3ecb93c-cce9-44a7-91a8-a5f3e7aa1dff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cheking: model.embed_tokens.weight\n",
      "Cheking: model.layers.0.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.0.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.0.self_attn.o_proj.weight\n",
      "Cheking: model.layers.0.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.0.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.0.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.0.mlp.down_proj.weight\n",
      "Cheking: model.layers.0.mlp.down_proj.absmax\n",
      "Cheking: model.layers.0.input_layernorm.weight\n",
      "Cheking: model.layers.0.post_attention_layernorm.weight\n",
      "Cheking: model.layers.1.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.1.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.1.self_attn.o_proj.weight\n",
      "Cheking: model.layers.1.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.1.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.1.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.1.mlp.down_proj.weight\n",
      "Cheking: model.layers.1.mlp.down_proj.absmax\n",
      "Cheking: model.layers.1.input_layernorm.weight\n",
      "Cheking: model.layers.1.post_attention_layernorm.weight\n",
      "Cheking: model.layers.2.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.2.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.2.self_attn.o_proj.weight\n",
      "Cheking: model.layers.2.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.2.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.2.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.2.mlp.down_proj.weight\n",
      "Cheking: model.layers.2.mlp.down_proj.absmax\n",
      "Cheking: model.layers.2.input_layernorm.weight\n",
      "Cheking: model.layers.2.post_attention_layernorm.weight\n",
      "Cheking: model.layers.3.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.3.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.3.self_attn.o_proj.weight\n",
      "Cheking: model.layers.3.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.3.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.3.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.3.mlp.down_proj.weight\n",
      "Cheking: model.layers.3.mlp.down_proj.absmax\n",
      "Cheking: model.layers.3.input_layernorm.weight\n",
      "Cheking: model.layers.3.post_attention_layernorm.weight\n",
      "Cheking: model.layers.4.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.4.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.4.self_attn.o_proj.weight\n",
      "Cheking: model.layers.4.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.4.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.4.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.4.mlp.down_proj.weight\n",
      "Cheking: model.layers.4.mlp.down_proj.absmax\n",
      "Cheking: model.layers.4.input_layernorm.weight\n",
      "Cheking: model.layers.4.post_attention_layernorm.weight\n",
      "Cheking: model.layers.5.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.5.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.5.self_attn.o_proj.weight\n",
      "Cheking: model.layers.5.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.5.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.5.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.5.mlp.down_proj.weight\n",
      "Cheking: model.layers.5.mlp.down_proj.absmax\n",
      "Cheking: model.layers.5.input_layernorm.weight\n",
      "Cheking: model.layers.5.post_attention_layernorm.weight\n",
      "Cheking: model.layers.6.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.6.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.6.self_attn.o_proj.weight\n",
      "Cheking: model.layers.6.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.6.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.6.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.6.mlp.down_proj.weight\n",
      "Cheking: model.layers.6.mlp.down_proj.absmax\n",
      "Cheking: model.layers.6.input_layernorm.weight\n",
      "Cheking: model.layers.6.post_attention_layernorm.weight\n",
      "Cheking: model.layers.7.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.7.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.7.self_attn.o_proj.weight\n",
      "Cheking: model.layers.7.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.7.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.7.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.7.mlp.down_proj.weight\n",
      "Cheking: model.layers.7.mlp.down_proj.absmax\n",
      "Cheking: model.layers.7.input_layernorm.weight\n",
      "Cheking: model.layers.7.post_attention_layernorm.weight\n",
      "Cheking: model.layers.8.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.8.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.8.self_attn.o_proj.weight\n",
      "Cheking: model.layers.8.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.8.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.8.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.8.mlp.down_proj.weight\n",
      "Cheking: model.layers.8.mlp.down_proj.absmax\n",
      "Cheking: model.layers.8.input_layernorm.weight\n",
      "Cheking: model.layers.8.post_attention_layernorm.weight\n",
      "Cheking: model.layers.9.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.9.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.9.self_attn.o_proj.weight\n",
      "Cheking: model.layers.9.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.9.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.9.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.9.mlp.down_proj.weight\n",
      "Cheking: model.layers.9.mlp.down_proj.absmax\n",
      "Cheking: model.layers.9.input_layernorm.weight\n",
      "Cheking: model.layers.9.post_attention_layernorm.weight\n",
      "Cheking: model.layers.10.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.10.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.10.self_attn.o_proj.weight\n",
      "Cheking: model.layers.10.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.10.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.10.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.10.mlp.down_proj.weight\n",
      "Cheking: model.layers.10.mlp.down_proj.absmax\n",
      "Cheking: model.layers.10.input_layernorm.weight\n",
      "Cheking: model.layers.10.post_attention_layernorm.weight\n",
      "Cheking: model.layers.11.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.11.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.11.self_attn.o_proj.weight\n",
      "Cheking: model.layers.11.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.11.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.11.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.11.mlp.down_proj.weight\n",
      "Cheking: model.layers.11.mlp.down_proj.absmax\n",
      "Cheking: model.layers.11.input_layernorm.weight\n",
      "Cheking: model.layers.11.post_attention_layernorm.weight\n",
      "Cheking: model.layers.12.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.12.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.12.self_attn.o_proj.weight\n",
      "Cheking: model.layers.12.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.12.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.12.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.12.mlp.down_proj.weight\n",
      "Cheking: model.layers.12.mlp.down_proj.absmax\n",
      "Cheking: model.layers.12.input_layernorm.weight\n",
      "Cheking: model.layers.12.post_attention_layernorm.weight\n",
      "Cheking: model.layers.13.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.13.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.13.self_attn.o_proj.weight\n",
      "Cheking: model.layers.13.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.13.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.13.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.13.mlp.down_proj.weight\n",
      "Cheking: model.layers.13.mlp.down_proj.absmax\n",
      "Cheking: model.layers.13.input_layernorm.weight\n",
      "Cheking: model.layers.13.post_attention_layernorm.weight\n",
      "Cheking: model.layers.14.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.14.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.14.self_attn.o_proj.weight\n",
      "Cheking: model.layers.14.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.14.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.14.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.14.mlp.down_proj.weight\n",
      "Cheking: model.layers.14.mlp.down_proj.absmax\n",
      "Cheking: model.layers.14.input_layernorm.weight\n",
      "Cheking: model.layers.14.post_attention_layernorm.weight\n",
      "Cheking: model.layers.15.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.15.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.15.self_attn.o_proj.weight\n",
      "Cheking: model.layers.15.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.15.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.15.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.15.mlp.down_proj.weight\n",
      "Cheking: model.layers.15.mlp.down_proj.absmax\n",
      "Cheking: model.layers.15.input_layernorm.weight\n",
      "Cheking: model.layers.15.post_attention_layernorm.weight\n",
      "Cheking: model.layers.16.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.16.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.16.self_attn.o_proj.weight\n",
      "Cheking: model.layers.16.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.16.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.16.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.16.mlp.down_proj.weight\n",
      "Cheking: model.layers.16.mlp.down_proj.absmax\n",
      "Cheking: model.layers.16.input_layernorm.weight\n",
      "Cheking: model.layers.16.post_attention_layernorm.weight\n",
      "Cheking: model.layers.17.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.17.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.17.self_attn.o_proj.weight\n",
      "Cheking: model.layers.17.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.17.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.17.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.17.mlp.down_proj.weight\n",
      "Cheking: model.layers.17.mlp.down_proj.absmax\n",
      "Cheking: model.layers.17.input_layernorm.weight\n",
      "Cheking: model.layers.17.post_attention_layernorm.weight\n",
      "Cheking: model.layers.18.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.18.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.18.self_attn.o_proj.weight\n",
      "Cheking: model.layers.18.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.18.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.18.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.18.mlp.down_proj.weight\n",
      "Cheking: model.layers.18.mlp.down_proj.absmax\n",
      "Cheking: model.layers.18.input_layernorm.weight\n",
      "Cheking: model.layers.18.post_attention_layernorm.weight\n",
      "Cheking: model.layers.19.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.19.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.19.self_attn.o_proj.weight\n",
      "Cheking: model.layers.19.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.19.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.19.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.19.mlp.down_proj.weight\n",
      "Cheking: model.layers.19.mlp.down_proj.absmax\n",
      "Cheking: model.layers.19.input_layernorm.weight\n",
      "Cheking: model.layers.19.post_attention_layernorm.weight\n",
      "Cheking: model.layers.20.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.20.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.20.self_attn.o_proj.weight\n",
      "Cheking: model.layers.20.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.20.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.20.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.20.mlp.down_proj.weight\n",
      "Cheking: model.layers.20.mlp.down_proj.absmax\n",
      "Cheking: model.layers.20.input_layernorm.weight\n",
      "Cheking: model.layers.20.post_attention_layernorm.weight\n",
      "Cheking: model.layers.21.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.21.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.21.self_attn.o_proj.weight\n",
      "Cheking: model.layers.21.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.21.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.21.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.21.mlp.down_proj.weight\n",
      "Cheking: model.layers.21.mlp.down_proj.absmax\n",
      "Cheking: model.layers.21.input_layernorm.weight\n",
      "Cheking: model.layers.21.post_attention_layernorm.weight\n",
      "Cheking: model.layers.22.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.22.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.22.self_attn.o_proj.weight\n",
      "Cheking: model.layers.22.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.22.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.22.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.22.mlp.down_proj.weight\n",
      "Cheking: model.layers.22.mlp.down_proj.absmax\n",
      "Cheking: model.layers.22.input_layernorm.weight\n",
      "Cheking: model.layers.22.post_attention_layernorm.weight\n",
      "Cheking: model.layers.23.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.23.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.23.self_attn.o_proj.weight\n",
      "Cheking: model.layers.23.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.23.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.23.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.23.mlp.down_proj.weight\n",
      "Cheking: model.layers.23.mlp.down_proj.absmax\n",
      "Cheking: model.layers.23.input_layernorm.weight\n",
      "Cheking: model.layers.23.post_attention_layernorm.weight\n",
      "Cheking: model.layers.24.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.24.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.24.self_attn.o_proj.weight\n",
      "Cheking: model.layers.24.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.24.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.24.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.24.mlp.down_proj.weight\n",
      "Cheking: model.layers.24.mlp.down_proj.absmax\n",
      "Cheking: model.layers.24.input_layernorm.weight\n",
      "Cheking: model.layers.24.post_attention_layernorm.weight\n",
      "Cheking: model.layers.25.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.25.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.25.self_attn.o_proj.weight\n",
      "Cheking: model.layers.25.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.25.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.25.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.25.mlp.down_proj.weight\n",
      "Cheking: model.layers.25.mlp.down_proj.absmax\n",
      "Cheking: model.layers.25.input_layernorm.weight\n",
      "Cheking: model.layers.25.post_attention_layernorm.weight\n",
      "Cheking: model.layers.26.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.26.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.26.self_attn.o_proj.weight\n",
      "Cheking: model.layers.26.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.26.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.26.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.26.mlp.down_proj.weight\n",
      "Cheking: model.layers.26.mlp.down_proj.absmax\n",
      "Cheking: model.layers.26.input_layernorm.weight\n",
      "Cheking: model.layers.26.post_attention_layernorm.weight\n",
      "Cheking: model.layers.27.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.27.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.27.self_attn.o_proj.weight\n",
      "Cheking: model.layers.27.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.27.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.27.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.27.mlp.down_proj.weight\n",
      "Cheking: model.layers.27.mlp.down_proj.absmax\n",
      "Cheking: model.layers.27.input_layernorm.weight\n",
      "Cheking: model.layers.27.post_attention_layernorm.weight\n",
      "Cheking: model.layers.28.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.28.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.28.self_attn.o_proj.weight\n",
      "Cheking: model.layers.28.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.28.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.28.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.28.mlp.down_proj.weight\n",
      "Cheking: model.layers.28.mlp.down_proj.absmax\n",
      "Cheking: model.layers.28.input_layernorm.weight\n",
      "Cheking: model.layers.28.post_attention_layernorm.weight\n",
      "Cheking: model.layers.29.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.29.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.29.self_attn.o_proj.weight\n",
      "Cheking: model.layers.29.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.29.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.29.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.29.mlp.down_proj.weight\n",
      "Cheking: model.layers.29.mlp.down_proj.absmax\n",
      "Cheking: model.layers.29.input_layernorm.weight\n",
      "Cheking: model.layers.29.post_attention_layernorm.weight\n",
      "Cheking: model.layers.30.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.30.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.30.self_attn.o_proj.weight\n",
      "Cheking: model.layers.30.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.30.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.30.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.30.mlp.down_proj.weight\n",
      "Cheking: model.layers.30.mlp.down_proj.absmax\n",
      "Cheking: model.layers.30.input_layernorm.weight\n",
      "Cheking: model.layers.30.post_attention_layernorm.weight\n",
      "Cheking: model.layers.31.self_attn.qkv_proj.weight\n",
      "Cheking: model.layers.31.self_attn.qkv_proj.absmax\n",
      "Cheking: model.layers.31.self_attn.o_proj.weight\n",
      "Cheking: model.layers.31.self_attn.o_proj.absmax\n",
      "Cheking: model.layers.31.mlp.gate_up_proj.weight\n",
      "Cheking: model.layers.31.mlp.gate_up_proj.absmax\n",
      "Cheking: model.layers.31.mlp.down_proj.weight\n",
      "Cheking: model.layers.31.mlp.down_proj.absmax\n",
      "Cheking: model.layers.31.input_layernorm.weight\n",
      "Cheking: model.layers.31.post_attention_layernorm.weight\n",
      "Cheking: model.norm.weight\n",
      "Cheking: lm_head.weight\n"
     ]
    }
   ],
   "source": [
    "# Sanity Check if weights are loaded correctly into vllm model.\n",
    "pack_factor = 2\n",
    "for n, p in model.named_parameters():\n",
    "\n",
    "    print(\"Cheking:\", n)\n",
    "    \n",
    "    if 'qkv_proj' in n:\n",
    "        if 'absmax' in n: continue\n",
    "        \n",
    "        # Loaded qkv\n",
    "        qkv_weight = model.get_parameter(n)\n",
    "        qkv_absmax = model.get_parameter(n.replace(\".weight\", \".absmax\"))\n",
    "        qkv_shape = [qkv_weight.shape[0], qkv_weight.shape[1] * pack_factor]\n",
    "        q_shape   = [qkv_weight.shape[0], qkv_weight.shape[1] * pack_factor // 3]\n",
    "        \n",
    "        absmax = qkv_absmax.contiguous().view(-1)\n",
    "        quant_state = create_quant_state(absmax, qkv_shape)\n",
    "        \n",
    "        W_dq = bnb.functional.dequantize_4bit(qkv_weight.contiguous().view(-1,1), quant_state=quant_state)\n",
    "\n",
    "        # Saved q proj\n",
    "        q_proj_weight_name = n.replace(\"qkv_proj\", \"q_proj\")\n",
    "        q_proj_absmax_name = n.replace(\"qkv_proj\", \"q_proj\").replace(\".weight\", \".absmax\")\n",
    "        \n",
    "        absmax = quantized_state_dict[q_proj_absmax_name].cuda().contiguous().view(-1)\n",
    "        quant_state = create_quant_state(absmax, q_shape)\n",
    "        \n",
    "        W_q_proj_dq = bnb.functional.dequantize_4bit(quantized_state_dict[q_proj_weight_name].contiguous().view(-1,1).cuda(), quant_state=quant_state)\n",
    "\n",
    "        # Compare with HF model state dict\n",
    "        param = Params4bit(hf_state_dict[q_proj_weight_name].t(), blocksize=64, compress_statistics=False, quant_type='nf4').cuda()\n",
    "        W_q_proj_dq_hf = dequantize_4bit(param.data, param.quant_state)\n",
    "        \n",
    "        # Saved k proj\n",
    "        k_proj_weight_name = n.replace(\"qkv_proj\", \"k_proj\")\n",
    "        k_proj_absmax_name = n.replace(\"qkv_proj\", \"k_proj\").replace(\".weight\", \".absmax\")\n",
    "        \n",
    "        absmax = quantized_state_dict[k_proj_absmax_name].cuda().contiguous().view(-1)\n",
    "        quant_state = create_quant_state(absmax, q_shape)\n",
    "        \n",
    "        W_k_proj_dq = bnb.functional.dequantize_4bit(quantized_state_dict[k_proj_weight_name].contiguous().view(-1,1).cuda(), quant_state=quant_state)\n",
    "\n",
    "        # Compare with HF model state dict\n",
    "        param = Params4bit(hf_state_dict[k_proj_weight_name].t(), blocksize=64, compress_statistics=False, quant_type='nf4').cuda()\n",
    "        W_k_proj_dq_hf = dequantize_4bit(param.data, param.quant_state)        \n",
    "\n",
    "        # Saved v proj\n",
    "        v_proj_weight_name = n.replace(\"qkv_proj\", \"v_proj\")\n",
    "        v_proj_absmax_name = n.replace(\"qkv_proj\", \"v_proj\").replace(\".weight\", \".absmax\")\n",
    "\n",
    "        absmax = quantized_state_dict[v_proj_absmax_name].cuda().contiguous().view(-1)\n",
    "        quant_state = create_quant_state(absmax, q_shape)\n",
    "\n",
    "        W_v_proj_dq = bnb.functional.dequantize_4bit(quantized_state_dict[v_proj_weight_name].contiguous().view(-1,1).cuda(), quant_state=quant_state)\n",
    "\n",
    "         # Compare with HF model state dict\n",
    "        param = Params4bit(hf_state_dict[v_proj_weight_name].t(), blocksize=64, compress_statistics=False, quant_type='nf4').cuda()\n",
    "        W_v_proj_dq_hf = dequantize_4bit(param.data, param.quant_state)       \n",
    "\n",
    "        # Check whether loaded vs saved weights are equal after dequantization.\n",
    "        assert torch.equal(W_dq, torch.cat([W_q_proj_dq, W_k_proj_dq, W_v_proj_dq], dim=1))\n",
    "\n",
    "        assert torch.equal(W_dq, torch.cat([W_q_proj_dq_hf, W_k_proj_dq_hf, W_v_proj_dq_hf], dim=1))\n",
    "    \n",
    "    \n",
    "    elif 'gate_up_proj' in n:\n",
    "        if 'absmax' in n: continue\n",
    "            \n",
    "        # Loaded gate_up\n",
    "        gate_up_weight = model.get_parameter(n)\n",
    "        gate_up_absmax = model.get_parameter(n.replace(\".weight\", \".absmax\"))\n",
    "        gate_up_shape = [gate_up_weight.shape[0], gate_up_weight.shape[1] * pack_factor]\n",
    "        gate_shape    = [gate_up_weight.shape[0], gate_up_weight.shape[1] * pack_factor // 2]\n",
    "\n",
    "        absmax = gate_up_absmax.contiguous().view(-1)\n",
    "        quant_state = create_quant_state(absmax, gate_up_shape)\n",
    "        \n",
    "        W_dq = bnb.functional.dequantize_4bit(gate_up_weight.contiguous().view(-1,1), quant_state=quant_state)\n",
    "\n",
    "        # Saved gate_proj\n",
    "        gate_proj_weight_name = n.replace(\"gate_up_proj\", \"gate_proj\")\n",
    "        gate_proj_absmax_name = n.replace(\"gate_up_proj\", \"gate_proj\").replace(\".weight\", \".absmax\")\n",
    "        \n",
    "        absmax = quantized_state_dict[gate_proj_absmax_name].cuda().contiguous().view(-1)\n",
    "        quant_state = create_quant_state(absmax, gate_shape)\n",
    "        \n",
    "        W_gate_proj_dq = bnb.functional.dequantize_4bit(quantized_state_dict[gate_proj_weight_name].contiguous().view(-1,1).cuda(), quant_state=quant_state)\n",
    "\n",
    "        # Saved up_proj\n",
    "        up_proj_weight_name = n.replace(\"gate_up_proj\", \"up_proj\")\n",
    "        up_proj_absmax_name = n.replace(\"gate_up_proj\", \"up_proj\").replace(\".weight\", \".absmax\")\n",
    "        \n",
    "        absmax = quantized_state_dict[up_proj_absmax_name].cuda().contiguous().view(-1)\n",
    "        quant_state = create_quant_state(absmax, gate_shape)\n",
    "\n",
    "        W_up_proj_dq = bnb.functional.dequantize_4bit(quantized_state_dict[up_proj_weight_name].contiguous().view(-1,1).cuda(), quant_state=quant_state)\n",
    "\n",
    "        # Check whether loaded vs saved weights are equal after dequantization.\n",
    "        assert torch.equal(W_dq, torch.cat([W_gate_proj_dq, W_up_proj_dq], dim=1))\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        # Check whether loaded vs saved weights are equal after dequantization.\n",
    "        assert torch.equal(quantized_state_dict[n].data, p.data.cpu())\n",
    "        \n",
    "        # Loaded gate_up\n",
    "        if any(l in n for l in [\"o_proj\", \"down_proj\"]):\n",
    "            if \"weight\" in n:\n",
    "                weight = model.get_parameter(n)\n",
    "                absmax = model.get_parameter(n.replace(\".weight\", \".absmax\"))\n",
    "                shape = [weight.shape[0], weight.shape[1] * pack_factor]\n",
    "                absmax = absmax.contiguous().view(-1)\n",
    "                quant_state = create_quant_state(absmax, shape)\n",
    "                W_dq = bnb.functional.dequantize_4bit(weight.contiguous().view(-1,1), quant_state=quant_state)\n",
    "\n",
    "                # Compare with HF model state dict\n",
    "                param = Params4bit(hf_state_dict[n].t(), blocksize=64, compress_statistics=False, quant_type='nf4').cuda()\n",
    "                assert torch.equal(W_dq, dequantize_4bit(param.data, param.quant_state))\n",
    "                \n",
    "        else:\n",
    "            # Compare with HF model state dict\n",
    "            assert torch.equal(quantized_state_dict[n].data, hf_state_dict[n])\n",
    "\n",
    "    \n",
    "    if any(l in n for l in [\"qkv_proj\", \"o_proj\", \"gate_up_proj\", \"down_proj\"]) and \"weight\" in n:\n",
    "        module = model.get_submodule(n.rpartition(\".\")[0])\n",
    "        input_size = module.weight.shape[0]\n",
    "        x = torch.randn(1,input_size).cuda().to(torch.bfloat16)\n",
    "        out1 = module(x)\n",
    "        if len(out1) > 1: out1 = out1[0]\n",
    "        out2 = x @ W_dq\n",
    "        \n",
    "        # Check forward pass is correct.\n",
    "        assert torch.equal(out1, out2)\n",
    "\n",
    "    # print(p.view(-1)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3e381a01-7457-4cf6-8994-bc9561af3269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check activations VLLM bnb vs HF bnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207aba1d-b5e5-42cb-b136-bd2fcdb06694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc74e0f2-b15e-4457-8ee2-85e67325aad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc2aa61-6684-4ce2-b8c7-c31a3a500697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43c4344-3699-4f0f-b3a5-ed2045c2c14c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde15183-ee7a-4c32-9406-8a5b4238f79d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32091d7a-06b4-488f-a37d-21d37fd1a59c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6e6dd3-f798-4ea0-8642-6448cffacaa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b433344-8ff8-432c-8638-776c9e2545c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e258bca3-acae-4213-b12b-d53b6a201751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5694bb7-06bf-4b63-9ddf-f633e3a3f690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b99cc-49cf-4b7e-a5c7-95c7f98bcba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
